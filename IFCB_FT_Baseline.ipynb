{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IFCB_FT_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNshTTuV/wHM/CMmYWttHqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pglez82/IFCB_semisupervised/blob/master/IFCB_FT_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysuTmf6SE9KB",
        "colab_type": "text"
      },
      "source": [
        "# Load the data\n",
        "We are going to finetune a resnet18 and extract features with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv08LtzkFGee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "90d7c4c1-d3fb-46b6-e4e1-612d3e424456"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isfile(\"IFCB_data.tar\") and not os.path.isdir(\"data\"):\n",
        "  print(\"Data do not exist in local. Downloading...\")\n",
        "  !wget -O IFCB_data.tar https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
        "else:\n",
        "  print(\"Data already exists. Skipping download.\")\n",
        "\n",
        "if not os.path.isdir(\"data\"):\n",
        "  print(\"Extracting the tar file...\")\n",
        "  !tar -xf \"IFCB_data.tar\"\n",
        "  print(\"Done. Removing the tar file.\")\n",
        "  !rm -f IFCB_data.tar #Remove the original file to save space"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data do not exist in local. Downloading...\n",
            "--2020-06-14 13:47:34--  https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
            "Resolving unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)... 13.107.136.9\n",
            "Connecting to unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/gonzalezgpablo_uniovi_es/Documents/IFCB/data/IFCB_data.tar?&originalPath=aHR0cHM6Ly91bmlvdmllZG8tbXkuc2hhcmVwb2ludC5jb20vOnU6L2cvcGVyc29uYWwvZ29uemFsZXpncGFibG9fdW5pb3ZpX2VzL0VjMnowdUM0bGdoRWctOU1qem9KOVFrQks1bjc0UWpTLUxzekI5ZGxOclBmYXc_cnRpbWU9b2NtQWZta1EyRWc [following]\n",
            "--2020-06-14 13:47:35--  https://unioviedo-my.sharepoint.com/personal/gonzalezgpablo_uniovi_es/Documents/IFCB/data/IFCB_data.tar?&originalPath=aHR0cHM6Ly91bmlvdmllZG8tbXkuc2hhcmVwb2ludC5jb20vOnU6L2cvcGVyc29uYWwvZ29uemFsZXpncGFibG9fdW5pb3ZpX2VzL0VjMnowdUM0bGdoRWctOU1qem9KOVFrQks1bjc0UWpTLUxzekI5ZGxOclBmYXc_cnRpbWU9b2NtQWZta1EyRWc\n",
            "Reusing existing connection to unioviedo-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16610365440 (15G) [application/x-tar]\n",
            "Saving to: ‘IFCB_data.tar’\n",
            "\n",
            "IFCB_data.tar        79%[==============>     ]  12.25G  47.5MB/s    in 3m 20s  \n",
            "\n",
            "2020-06-14 13:50:55 (62.7 MB/s) - Read error at byte 13155610323/16610365440 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2020-06-14 13:50:56--  (try: 2)  https://unioviedo-my.sharepoint.com/personal/gonzalezgpablo_uniovi_es/Documents/IFCB/data/IFCB_data.tar?&originalPath=aHR0cHM6Ly91bmlvdmllZG8tbXkuc2hhcmVwb2ludC5jb20vOnU6L2cvcGVyc29uYWwvZ29uemFsZXpncGFibG9fdW5pb3ZpX2VzL0VjMnowdUM0bGdoRWctOU1qem9KOVFrQks1bjc0UWpTLUxzekI5ZGxOclBmYXc_cnRpbWU9b2NtQWZta1EyRWc\n",
            "Connecting to unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 PARTIAL CONTENT\n",
            "Length: 16610365440 (15G), 3454755117 (3.2G) remaining [application/x-tar]\n",
            "Saving to: ‘IFCB_data.tar’\n",
            "\n",
            "IFCB_data.tar       100%[+++++++++++++++====>]  15.47G  58.7MB/s    in 57s     \n",
            "\n",
            "2020-06-14 13:51:54 (58.1 MB/s) - ‘IFCB_data.tar’ saved [16610365440/16610365440]\n",
            "\n",
            "Extracting the tar file...\n",
            "Done. Removing the tar file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUG0AmQ6z8us",
        "colab_type": "text"
      },
      "source": [
        "# Download CSV with information about the images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoVqmVot04VX",
        "colab_type": "code",
        "outputId": "910ef3f7-1876-4e8f-91ff-7ff22bc3d551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "if not os.path.isfile('IFCB.csv.zip'):\n",
        "  print(\"CSV data do not exist. Downloading...\")\n",
        "  !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
        "\n",
        "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
        "print(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CSV data do not exist. Downloading...\n",
            "--2020-06-14 14:01:12--  https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\n",
            "Resolving unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)... 13.107.136.9\n",
            "Connecting to unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/gonzalezgpablo_uniovi_es/Documents/IFCB/data/IFCB.csv.zip?&originalPath=aHR0cHM6Ly91bmlvdmllZG8tbXkuc2hhcmVwb2ludC5jb20vOnU6L2cvcGVyc29uYWwvZ29uemFsZXpncGFibG9fdW5pb3ZpX2VzL0Vmc1ZMaEZzWUpwUGpPMEtabHBXVXEwQlU2TGFxSjk4OVJlNFh6YXRTOWFHNFE_cnRpbWU9dlRwQ1ptc1EyRWc [following]\n",
            "--2020-06-14 14:01:13--  https://unioviedo-my.sharepoint.com/personal/gonzalezgpablo_uniovi_es/Documents/IFCB/data/IFCB.csv.zip?&originalPath=aHR0cHM6Ly91bmlvdmllZG8tbXkuc2hhcmVwb2ludC5jb20vOnU6L2cvcGVyc29uYWwvZ29uemFsZXpncGFibG9fdW5pb3ZpX2VzL0Vmc1ZMaEZzWUpwUGpPMEtabHBXVXEwQlU2TGFxSjk4OVJlNFh6YXRTOWFHNFE_cnRpbWU9dlRwQ1ptc1EyRWc\n",
            "Reusing existing connection to unioviedo-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8702881 (8.3M) [application/x-zip-compressed]\n",
            "Saving to: ‘IFCB.csv.zip’\n",
            "\n",
            "IFCB.csv.zip        100%[===================>]   8.30M  8.57MB/s    in 1.0s    \n",
            "\n",
            "2020-06-14 14:01:15 (8.57 MB/s) - ‘IFCB.csv.zip’ saved [8702881/8702881]\n",
            "\n",
            "                        Sample  roi_number  ...       AutoClass FunctionalGroup\n",
            "0        IFCB1_2006_158_000036           1  ...             mix      Flagellate\n",
            "1        IFCB1_2006_158_000036           2  ...     ciliate_mix         Ciliate\n",
            "2        IFCB1_2006_158_000036           3  ...             mix      Flagellate\n",
            "3        IFCB1_2006_158_000036           4  ...             mix      Flagellate\n",
            "4        IFCB1_2006_158_000036           5  ...             mix      Flagellate\n",
            "...                        ...         ...  ...             ...             ...\n",
            "3457814  IFCB5_2014_353_205141        6850  ...  Leptocylindrus          Diatom\n",
            "3457815  IFCB5_2014_353_205141        6852  ...             mix      Flagellate\n",
            "3457816  IFCB5_2014_353_205141        6855  ...             mix      Flagellate\n",
            "3457817  IFCB5_2014_353_205141        6856  ...             mix      Flagellate\n",
            "3457818  IFCB5_2014_353_205141        6857  ...             mix      Flagellate\n",
            "\n",
            "[3457819 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB1gMsg5EIZV",
        "colab_type": "text"
      },
      "source": [
        "# Create training set\n",
        "\n",
        "Here we make a reestructuration of the images depending on which class we consider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX4-tijiEVcO",
        "colab_type": "code",
        "outputId": "73a7f434-351d-48bc-9340-6313c69c3a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "import progressbar\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "classcolumn = \"AutoClass\" #Autoclass means 51 classes\n",
        "yearstraining = ['2006'] #Years to consider as training\n",
        "yearsvalidation = ['2007']\n",
        "trainingfolder = \"training\"\n",
        "validationfolder = \"validation\"\n",
        "\n",
        "classes = pd.unique(data[classcolumn])\n",
        "print(\"Considering %i classes\" % len(classes))\n",
        "\n",
        "print(\"Computing image paths...\")\n",
        "#Compute data paths\n",
        "data['year'] = data['Sample'].str[6:10].astype(str)\n",
        "data['path']=\"data\"+'/'+data['year']+'/'+data['OriginalClass'].astype(str)+'/'+data['Sample'].astype(str)+'_'+data['roi_number'].apply(lambda x: str(x).zfill(5))+'.png'\n",
        "print('Done')\n",
        "\n",
        "if not os.path.isdir(trainingfolder):\n",
        "  print(\"Create folder structure for training set...\")\n",
        "  os.mkdir(trainingfolder)\n",
        "  for folder in classes:\n",
        "    os.mkdir(os.path.join(trainingfolder,folder))\n",
        "  print(\"Done.\\nMoving images to the respective folders...\")\n",
        "  data[data['year'].isin(yearstraining)].progress_apply(lambda row: os.rename(row['path'],os.path.join(trainingfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
        "  print(\"Done\")\n",
        "else:\n",
        "  print(\"Training data already there... Doing nothing\")\n",
        "\n",
        "if not os.path.isdir(validationfolder):\n",
        "  print(\"Create folder structure for the validation set...\")\n",
        "  os.mkdir(validationfolder)\n",
        "  for folder in classes:\n",
        "    os.mkdir(os.path.join(validationfolder,folder))\n",
        "  print(\"Done.\\nMoving images to the respective folders...\")\n",
        "  data[data['year'].isin(yearsvalidation)].progress_apply(lambda row: os.rename(row['path'],os.path.join(validationfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
        "  print(\"Done\")  \n",
        "else:\n",
        "  print(\"Validation data already there... Doing nothing\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Considering 51 classes\n",
            "Computing image paths...\n",
            "Done\n",
            "Create folder structure for training set...\n",
            "Done.\n",
            "Moving images to the respective folders...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 131002/131002 [00:11<00:00, 11191.31it/s]\n",
            "  0%|          | 425/273080 [00:00<01:04, 4246.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Create folder structure for the validation set...\n",
            "Done.\n",
            "Moving images to the respective folders...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 273080/273080 [00:25<00:00, 10783.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clYlSmqOJofK",
        "colab_type": "text"
      },
      "source": [
        "# Configure the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW90Az7wJqhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "136a8a73-3eab-482c-af6a-6d74b924f2c2"
      },
      "source": [
        "import torch\n",
        "\n",
        "num_workers = 16 # @param\n",
        "batch_size = 64 # @param \n",
        "train_dir = './training'\n",
        "num_epochs_ft1 = 10 # @param\n",
        "num_epochs_ft2 = 10 # @param\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using %s\"%device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uahB4puIqI_",
        "colab_type": "text"
      },
      "source": [
        "# Prepare de DataLoaders for the CNN\n",
        "In this step it is important to consider that we have to use images with the same size than the original network (so we can reuse the weights)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbzJMEKsI2Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "#Define transofrmations\n",
        "train_transform = T.Compose([\n",
        "  T.Resize(size=256),\n",
        "  T.RandomResizedCrop(size=224),\n",
        "  T.RandomHorizontalFlip(),\n",
        "  T.ToTensor(),            \n",
        "  T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "#Define data loader\n",
        "train_dset = ImageFolder(train_dir, transform=train_transform)\n",
        "train_loader = DataLoader(train_dset,batch_size=batch_size,num_workers=num_workers,shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scu2GJIaKXAM",
        "colab_type": "text"
      },
      "source": [
        "# Load the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTq6OVVjKZjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fd5a702-6dc1-47a5-8d47-f25663febb5d"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "print(\"Adjusting the CNN for %s classes\" % len(train_dset.classes))\n",
        "num_classes = len(train_dset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "#Define loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjusting the CNN for 51 classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_W0lTw-LmHt",
        "colab_type": "text"
      },
      "source": [
        "# Perform finetuning\n",
        "First we only update the last layer for a few epochs, then we update all the weights with a small learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s5zIymPLtFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "396dcce1-c13f-4739-ad01-26763d62871e"
      },
      "source": [
        "import time\n",
        "\n",
        "def run_epoch(model, loss_fn, loader, optimizer, device):\n",
        "  \"\"\"\n",
        "  Train the model for one epoch.\n",
        "  \"\"\"\n",
        "  start_time = time.time()\n",
        "  # Set the model to training mode\n",
        "  model.train()\n",
        "  for step, (x, y) in enumerate(loader):\n",
        "    \n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Run the model forward to compute scores and loss.\n",
        "    scores = model(x)\n",
        "    loss = loss_fn(scores, y)\n",
        "\n",
        "    # Run the model backward and take a step using the optimizer.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 5 == 0:\n",
        "      spent = time.time()-start_time\n",
        "      print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()} \\t Time: {spent} secs [{(batch_size*5)/spent} ej/sec]]\")\n",
        "      start_time = time.time()\n",
        "\n",
        "def check_accuracy(model, loader, device):\n",
        "  \"\"\"\n",
        "  Check the accuracy of the model.\n",
        "  \"\"\"\n",
        "  # Set the model to eval mode\n",
        "  model.eval()\n",
        "  num_correct, num_samples = 0, 0\n",
        "  for x, y in loader:\n",
        "    x = x.to(device)\n",
        "\n",
        "    # Run the model forward, and compare the argmax score with the ground-truth\n",
        "    # category.\n",
        "    scores = model(x)\n",
        "    _, preds = scores.data.cpu().max(1)\n",
        "    num_correct += (preds == y).sum()\n",
        "    num_examples += x.size(0)\n",
        "\n",
        "  # Return the fraction of datapoints that were correctly classified.\n",
        "  acc = float(num_correct) / num_examples\n",
        "  return acc\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "#First phase of finetuning\n",
        "for epoch in range(num_epochs_ft1):\n",
        "  # Run an epoch over the training data.\n",
        "  print('Starting epoch %d / %d' % (epoch + 1,num_epochs_ft1))\n",
        "  run_epoch(model, loss_fn, train_loader, optimizer, device)\n",
        "\n",
        "  # Check accuracy on the train and val sets.\n",
        "  train_acc = check_accuracy(model, train_loader, device)\n",
        "  print('Train accuracy: ', train_acc)\n",
        "\n",
        "#Allow updating all the weights in the second phase\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "#Lower learning rate this time\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Train the entire model for a few more epochs, checking accuracy on the\n",
        "# train sets after each epoch.\n",
        "for epoch in range(num_epochs_ft2):\n",
        "  print('Starting epoch %d / %d' % (epoch + 1, num_epochs_ft2))\n",
        "  run_epoch(model, loss_fn, train_loader, optimizer, dtype)\n",
        "\n",
        "  train_acc = check_accuracy(model, train_loader, device)\n",
        "  val_acc = check_accuracy(model, val_loader, device)\n",
        "  print('Train accuracy: ', train_acc)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 10\n",
            "Step [0/2047]\t Loss: 1.7301113605499268 \t Time: 18.878816843032837 secs [16.950214765079142 ej/sec]]\n",
            "Step [5/2047]\t Loss: 1.6462788581848145 \t Time: 27.680025815963745 secs [11.560682859459192 ej/sec]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9a33fef8cddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;31m# Run an epoch over the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting epoch %d / %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs_ft1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# Check accuracy on the train and val sets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9a33fef8cddf>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loss_fn, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Run the model forward to compute scores and loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}