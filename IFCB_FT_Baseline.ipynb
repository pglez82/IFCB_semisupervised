{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pglez82/IFCB_semisupervised/blob/master/IFCB_FT_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysuTmf6SE9KB"
   },
   "source": [
    "# Load the data\n",
    "We are going to finetune a resnet18 and extract features with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "Iv08LtzkFGee",
    "outputId": "90d7c4c1-d3fb-46b6-e4e1-612d3e424456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if not os.path.isfile(\"IFCB_data.tar\") and not os.path.isdir(\"data\"):\n",
    "  print(\"Data do not exist in local. Downloading...\")\n",
    "  !wget -O IFCB_data.tar https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
    "else:\n",
    "  print(\"Data already exists. Skipping download.\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "  print(\"Extracting the tar file...\")\n",
    "  !tar -xf \"IFCB_data.tar\"\n",
    "  print(\"Done. Removing the tar file.\")\n",
    "  !rm -f IFCB_data.tar #Remove the original file to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hUG0AmQ6z8us"
   },
   "source": [
    "# Download CSV with information about the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "YoVqmVot04VX",
    "outputId": "910ef3f7-1876-4e8f-91ff-7ff22bc3d551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Sample  roi_number        OriginalClass  \\\n",
      "0        IFCB1_2006_158_000036           1                  mix   \n",
      "1        IFCB1_2006_158_000036           2  Tontonia_gracillima   \n",
      "2        IFCB1_2006_158_000036           3                  mix   \n",
      "3        IFCB1_2006_158_000036           4                  mix   \n",
      "4        IFCB1_2006_158_000036           5                  mix   \n",
      "...                        ...         ...                  ...   \n",
      "3457814  IFCB5_2014_353_205141        6850       Leptocylindrus   \n",
      "3457815  IFCB5_2014_353_205141        6852                  mix   \n",
      "3457816  IFCB5_2014_353_205141        6855                  mix   \n",
      "3457817  IFCB5_2014_353_205141        6856                  mix   \n",
      "3457818  IFCB5_2014_353_205141        6857                  mix   \n",
      "\n",
      "              AutoClass FunctionalGroup  \n",
      "0                   mix      Flagellate  \n",
      "1           ciliate_mix         Ciliate  \n",
      "2                   mix      Flagellate  \n",
      "3                   mix      Flagellate  \n",
      "4                   mix      Flagellate  \n",
      "...                 ...             ...  \n",
      "3457814  Leptocylindrus          Diatom  \n",
      "3457815             mix      Flagellate  \n",
      "3457816             mix      Flagellate  \n",
      "3457817             mix      Flagellate  \n",
      "3457818             mix      Flagellate  \n",
      "\n",
      "[3457819 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.isfile('IFCB.csv.zip'):\n",
    "  print(\"CSV data do not exist. Downloading...\")\n",
    "  !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
    "\n",
    "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oB1gMsg5EIZV"
   },
   "source": [
    "# Create training set\n",
    "\n",
    "Here we make a reestructuration of the images depending on which class we consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "fX4-tijiEVcO",
    "outputId": "73a7f434-351d-48bc-9340-6313c69c3a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering 51 classes\n",
      "Computing image paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgonzalez/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Training data already there... Doing nothing\n",
      "Validation data already there... Doing nothing\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "classcolumn = \"AutoClass\" #Autoclass means 51 classes\n",
    "yearstraining = ['2006'] #Years to consider as training\n",
    "yearsvalidation = ['2007']\n",
    "trainingfolder = \"training\"\n",
    "validationfolder = \"validation\"\n",
    "\n",
    "classes = pd.unique(data[classcolumn])\n",
    "print(\"Considering %i classes\" % len(classes))\n",
    "\n",
    "print(\"Computing image paths...\")\n",
    "#Compute data paths\n",
    "data['year'] = data['Sample'].str[6:10].astype(str)\n",
    "data['path']=\"data\"+'/'+data['year']+'/'+data['OriginalClass'].astype(str)+'/'+data['Sample'].astype(str)+'_'+data['roi_number'].apply(lambda x: str(x).zfill(5))+'.png'\n",
    "print('Done')\n",
    "\n",
    "if not os.path.isdir(trainingfolder):\n",
    "  print(\"Create folder structure for training set...\")\n",
    "  os.mkdir(trainingfolder)\n",
    "  for folder in classes:\n",
    "    os.mkdir(os.path.join(trainingfolder,folder))\n",
    "  print(\"Done.\\nMoving images to the respective folders...\")\n",
    "  data[data['year'].isin(yearstraining)].progress_apply(lambda row: os.rename(row['path'],os.path.join(trainingfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
    "  print(\"Done\")\n",
    "else:\n",
    "  print(\"Training data already there... Doing nothing\")\n",
    "\n",
    "if not os.path.isdir(validationfolder):\n",
    "  print(\"Create folder structure for the validation set...\")\n",
    "  os.mkdir(validationfolder)\n",
    "  for folder in classes:\n",
    "    os.mkdir(os.path.join(validationfolder,folder))\n",
    "  print(\"Done.\\nMoving images to the respective folders...\")\n",
    "  data[data['year'].isin(yearsvalidation)].progress_apply(lambda row: os.rename(row['path'],os.path.join(validationfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
    "  print(\"Done\")  \n",
    "else:\n",
    "  print(\"Validation data already there... Doing nothing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clYlSmqOJofK"
   },
   "source": [
    "# Configure the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jW90Az7wJqhD",
    "outputId": "136a8a73-3eab-482c-af6a-6d74b924f2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_workers = 16 # @param\n",
    "batch_size = 256 # @param \n",
    "train_dir = './training'\n",
    "val_dir = './validation'\n",
    "num_epochs_ft1 = 10 # @param\n",
    "num_epochs_ft2 = 10 # @param\n",
    "proportion = 0.01 #How many labelled examples do we take\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using %s\"%device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uahB4puIqI_"
   },
   "source": [
    "# Prepare de DataLoaders for the CNN\n",
    "In this step it is important to consider that we have to use images with the same size than the original network (so we can reuse the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbzJMEKsI2Kx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building subset with 1306 elements\n",
      "Working with 0.010000 of the current data\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def create_balanced_splits(train_loader,proportions):\n",
    "  \"\"\"\n",
    "  This function creates different balanced splits following the proportions\n",
    "  \"\"\"\n",
    "  labels_vector = []\n",
    "  for x,y in train_loader:\n",
    "    labels_vector.extend(y.numpy())\n",
    "  unique, globalcounts = np.unique(labels_vector, return_counts=True)\n",
    "  #Find indexes for each class\n",
    "  classindexes = []\n",
    "  for c in unique:\n",
    "    classindexes.append(np.where(labels_vector == c)[0])\n",
    "  subsets = {}\n",
    "  for p in proportions:\n",
    "    subsets[p]=[]\n",
    "    counts = np.rint(globalcounts*p)\n",
    "    print(\"Building subset with %d elements\"%sum(counts))\n",
    "    for i in range(len(counts)):\n",
    "      subsets[p].extend(classindexes[i][0:int(counts[i])])\n",
    "  return subsets\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "#Define transofrmations\n",
    "train_transform = T.Compose([\n",
    "  T.Resize(size=256),\n",
    "  T.RandomResizedCrop(size=224),\n",
    "  T.RandomHorizontalFlip(),\n",
    "  T.ToTensor(),            \n",
    "  T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "  T.Resize(size=256),\n",
    "  T.CenterCrop(size=224),\n",
    "  T.ToTensor(),\n",
    "  T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "  \n",
    "\n",
    "#Define data loader\n",
    "train_dset = ImageFolder(train_dir, transform=train_transform)\n",
    "train_loader = DataLoader(train_dset,batch_size=batch_size,num_workers=num_workers,shuffle=False)\n",
    "num_classes = len(train_dset.classes)\n",
    "indexes=create_balanced_splits(train_loader,[proportion])[proportion] #We only pass one value, this function if prepared to receive multiple proportions\n",
    "train_dset=torch.utils.data.Subset(train_dset,indexes)\n",
    "train_loader = DataLoader(train_dset,batch_size=batch_size,num_workers=num_workers,shuffle=False)\n",
    "print(\"Working with %f of the current data\"%proportion)\n",
    "\n",
    "val_dset = ImageFolder(val_dir, transform=val_transform)\n",
    "val_loader = DataLoader(val_dset,batch_size=batch_size,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scu2GJIaKXAM"
   },
   "source": [
    "# Load the CNN\n",
    "In this step we download a pretrained CNN with the weights from ImageNet. We change the last layer to match the number of classes that we have in our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oTq6OVVjKZjm",
    "outputId": "7fd5a702-6dc1-47a5-8d47-f25663febb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the CNN for 51 classes\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "print(\"Adjusting the CNN for %s classes\" % num_classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "#Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_W0lTw-LmHt"
   },
   "source": [
    "# Perform finetuning\n",
    "First we only update the last layer for a few epochs, then we update all the weights with a small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "1s5zIymPLtFc",
    "outputId": "396dcce1-c13f-4739-ad01-26763d62871e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 3\n",
      "Step [0/6]\t Loss: 3.9881646633148193 \t Time: 1.9066901206970215 secs [6713.204133727169 ej/sec]]\n",
      "Epoch [1/3]\t Loss: 0.8638995488484701\n",
      "Starting epoch 2 / 3\n",
      "Step [0/6]\t Loss: 2.483607530593872 \t Time: 1.8816590309143066 secs [6802.507675251038 ej/sec]]\n",
      "Epoch [2/3]\t Loss: 0.7111682891845703\n",
      "Starting epoch 3 / 3\n",
      "Step [0/6]\t Loss: 3.6970858573913574 \t Time: 1.8982470035552979 secs [6743.06345592876 ej/sec]]\n",
      "Epoch [3/3]\t Loss: 0.64537247021993\n",
      "Starting epoch 1 / 3\n",
      "Step [0/6]\t Loss: 4.781407833099365 \t Time: 1.9699621200561523 secs [6497.58686711963 ej/sec]]\n",
      "Epoch [1/3]\t Loss: 0.64537247021993\n",
      "Starting epoch 2 / 3\n",
      "Step [0/6]\t Loss: 4.5698418617248535 \t Time: 1.9369733333587646 secs [6608.247919347682 ej/sec]]\n",
      "Epoch [2/3]\t Loss: 0.64537247021993\n",
      "Starting epoch 3 / 3\n",
      "Step [0/6]\t Loss: 4.473696708679199 \t Time: 1.8982255458831787 secs [6743.139679981813 ej/sec]]\n",
      "Epoch [3/3]\t Loss: 0.64537247021993\n",
      "Val accuracy:  0.7289165007029054\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def run_epoch(model, loss_fn, loader, optimizer, device):\n",
    "  \"\"\"\n",
    "  Train the model for one epoch.\n",
    "  \"\"\"\n",
    "  loss_epoch = 0\n",
    "  start_time = time.time()\n",
    "  # Set the model to training mode\n",
    "  model.train()\n",
    "  for step, (x, y) in enumerate(loader):\n",
    "    \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Run the model forward to compute scores and loss.\n",
    "    scores = model(x)\n",
    "    loss = loss_fn(scores, y)\n",
    "    loss_epoch =+ loss.item()\n",
    "    # Run the model backward and take a step using the optimizer.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 50== 0:\n",
    "      spent = time.time()-start_time\n",
    "      print(f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()} \\t Time: {spent} secs [{(batch_size*50)/spent} ej/sec]]\")\n",
    "      start_time = time.time()\n",
    "  return loss_epoch\n",
    "\n",
    "def check_accuracy(model, loader, device):\n",
    "  \"\"\"\n",
    "  Check the accuracy of the model.\n",
    "  \"\"\"\n",
    "  # Set the model to eval mode\n",
    "  accuracy_epoch = 0\n",
    "  model.eval()\n",
    "  num_correct, num_examples = 0, 0\n",
    "  for x, y in loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # Run the model forward, and compare the argmax score with the ground-truth\n",
    "    # category.\n",
    "    output = model(x)\n",
    "    #_, preds = scores.data.cpu().max(1)\n",
    "    #num_correct += (preds == y).sum()\n",
    "    #num_examples += x.size(0)\n",
    "    predicted = output.argmax(1)\n",
    "    acc = (predicted == y).sum().item() / y.size(0)\n",
    "    accuracy_epoch += acc\n",
    "\n",
    "  # Return the fraction of datapoints that were correctly classified.\n",
    "  #acc = float(num_correct) / num_examples\n",
    "  accuracy_epoch = float(accuracy_epoch) / len(loader)\n",
    "  return accuracy_epoch\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "#First phase of finetuning\n",
    "for epoch in range(num_epochs_ft1):\n",
    "  # Run an epoch over the training data.\n",
    "  print('Starting epoch %d / %d' % (epoch + 1,num_epochs_ft1))\n",
    "  loss_epoch=run_epoch(model, loss_fn, train_loader, optimizer, device)\n",
    "\n",
    "  # Check accuracy on the train and val sets.\n",
    "  #train_acc = check_accuracy(model, train_loader, device)\n",
    "  print(f\"Epoch [{epoch+1}/{num_epochs_ft1}]\\t Loss: {loss_epoch / len(train_loader)}\")\n",
    "\n",
    "#Allow updating all the weights in the second phase\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "#Lower learning rate this time\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the entire model for a few more epochs, checking accuracy on the\n",
    "# train sets after each epoch.\n",
    "for epoch in range(num_epochs_ft2):\n",
    "  print('Starting epoch %d / %d' % (epoch + 1, num_epochs_ft2))\n",
    "  run_epoch(model, loss_fn, train_loader, optimizer, device)\n",
    "\n",
    "  print(f\"Epoch [{epoch+1}/{num_epochs_ft2}]\\t Loss: {loss_epoch / len(train_loader)}\")\n",
    "    \n",
    "print(\"Performing final validation in test examples...\")\n",
    "val_acc = check_accuracy(model, val_loader, device)\n",
    "print('Val accuracy: ', val_acc)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNshTTuV/wHM/CMmYWttHqR",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "IFCB_FT_Baseline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
