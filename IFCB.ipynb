{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pglez82/IFCB_semisupervised/blob/master/IFCB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RStEOrZz2isi"
   },
   "source": [
    "# Showing system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Mdydmkeg2pHa",
    "outputId": "f586782b-58b6-4b4e-c49b-5060260cb783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 14 20:53:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:17:00.0 Off |                  N/A |\n",
      "| 50%   78C    P2   223W / 250W |   4073MiB / 12196MiB |     68%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 23%   40C    P8    10W / 250W |     10MiB / 12194MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     24316      C   /home/pgonzalez/anaconda3/bin/python        4063MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Your runtime has 67.2 gigabytes of available RAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aj37uariCNh"
   },
   "source": [
    "# Download SimCLR code\n",
    "In this step we download the SimCLR code for **PyTorch** and install its dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "colab_type": "code",
    "id": "RU38uvtmh_HO",
    "outputId": "816d3c4a-588d-44fa-e1a5-ec3dcfa383e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/HDD/pgonzalez/IFCB_semisupervised/SimCLR\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "\n",
      "CondaValueError: prefix already exists: /home/pgonzalez/anaconda3/envs/simclr\n",
      "\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "Ran pip subprocess with arguments:\n",
      "['/home/pgonzalez/anaconda3/envs/simclr/bin/python', '-m', 'pip', 'install', '-U', '-r', '/media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Requirement already up-to-date: sacred in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from -r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: docopt<1.0,>=0.3 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: colorama>=0.4 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=18.0 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: munch<3.0,>=2.0.2 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: GitPython in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2.0,>=1.0 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: py-cpuinfo>=4.0 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonpickle<2.0,>=1.2 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from packaging>=18.0->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from packaging>=18.0->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from GitPython->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (4.0.5)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from jsonpickle<2.0,>=1.2->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/pgonzalez/anaconda3/envs/simclr/lib/python3.8/site-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred->-r /media/HDD/pgonzalez/IFCB_semisupervised/SimCLR/condaenv.1wm6vo11.requirements.txt (line 1)) (3.1.0)\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate simclr\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Processing /home/pgonzalez/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653/PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.3\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"SimCLR\"):\n",
    "  !git clone https://github.com/pglez82/SimCLR.git\n",
    " \n",
    "%cd SimCLR\n",
    "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
    "!pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofyw_2IYzlMu"
   },
   "source": [
    "# Download the images\n",
    "In this section, we **donwload** the data and **uncompress** it. The code has checks in order to ensure that already downloaded data is not redownloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zA0THo_kbFMw",
    "outputId": "d1361d8d-fc71-456f-f7bc-f0c34bbb2088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/HDD/pgonzalez/IFCB_semisupervised\n",
      "Data already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "if not os.path.isfile(\"IFCB_data.tar\") and not os.path.isdir(\"data\"):\n",
    "  print(\"Data do not exist in local. Downloading...\")\n",
    "  !wget -O IFCB_data.tar https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
    "else:\n",
    "  print(\"Data already exists. Skipping download.\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "  print(\"Extracting the tar file...\")\n",
    "  !tar -xf \"IFCB_data.tar\"\n",
    "  print(\"Done. Removing the tar file.\")\n",
    "  !rm -f IFCB_data.tar #Remove the original file to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hUG0AmQ6z8us"
   },
   "source": [
    "# Download CSV with information about the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "YoVqmVot04VX",
    "outputId": "d7d8544a-5d77-4d64-dcf1-a368e1bbadca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Sample  roi_number        OriginalClass  \\\n",
      "0        IFCB1_2006_158_000036           1                  mix   \n",
      "1        IFCB1_2006_158_000036           2  Tontonia_gracillima   \n",
      "2        IFCB1_2006_158_000036           3                  mix   \n",
      "3        IFCB1_2006_158_000036           4                  mix   \n",
      "4        IFCB1_2006_158_000036           5                  mix   \n",
      "...                        ...         ...                  ...   \n",
      "3457814  IFCB5_2014_353_205141        6850       Leptocylindrus   \n",
      "3457815  IFCB5_2014_353_205141        6852                  mix   \n",
      "3457816  IFCB5_2014_353_205141        6855                  mix   \n",
      "3457817  IFCB5_2014_353_205141        6856                  mix   \n",
      "3457818  IFCB5_2014_353_205141        6857                  mix   \n",
      "\n",
      "              AutoClass FunctionalGroup  \n",
      "0                   mix      Flagellate  \n",
      "1           ciliate_mix         Ciliate  \n",
      "2                   mix      Flagellate  \n",
      "3                   mix      Flagellate  \n",
      "4                   mix      Flagellate  \n",
      "...                 ...             ...  \n",
      "3457814  Leptocylindrus          Diatom  \n",
      "3457815             mix      Flagellate  \n",
      "3457816             mix      Flagellate  \n",
      "3457817             mix      Flagellate  \n",
      "3457818             mix      Flagellate  \n",
      "\n",
      "[3457819 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.isfile('IFCB.csv.zip'):\n",
    "  print(\"CSV data do not exist. Downloading...\")\n",
    "  !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
    "\n",
    "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oB1gMsg5EIZV"
   },
   "source": [
    "# Create training set\n",
    "\n",
    "Here we make a reestructuration of the images depending on which class we consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "fX4-tijiEVcO",
    "outputId": "eebbc197-ec2d-4b57-ae36-798ed164b172"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgonzalez/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering 51 classes\n",
      "Computing image paths...\n",
      "Done\n",
      "Training data already there... Doing nothing\n",
      "Validation data already there... Doing nothing\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "classcolumn = \"AutoClass\" #Autoclass means 51 classes\n",
    "yearstraining = ['2006'] #Years to consider as training\n",
    "yearsvalidation = ['2007']\n",
    "trainingfolder = \"training\"\n",
    "validationfolder = \"validation\"\n",
    "\n",
    "classes = pd.unique(data[classcolumn])\n",
    "print(\"Considering %i classes\" % len(classes))\n",
    "\n",
    "print(\"Computing image paths...\")\n",
    "#Compute data paths\n",
    "data['year'] = data['Sample'].str[6:10].astype(str)\n",
    "data['path']=\"data\"+'/'+data['year']+'/'+data['OriginalClass'].astype(str)+'/'+data['Sample'].astype(str)+'_'+data['roi_number'].apply(lambda x: str(x).zfill(5))+'.png'\n",
    "print('Done')\n",
    "\n",
    "if not os.path.isdir(trainingfolder):\n",
    "  print(\"Create folder structure for training set...\")\n",
    "  os.mkdir(trainingfolder)\n",
    "  for folder in classes:\n",
    "    os.mkdir(os.path.join(trainingfolder,folder))\n",
    "  print(\"Done.\\nMoving images to the respective folders...\")\n",
    "  data[data['year'].isin(yearstraining)].progress_apply(lambda row: os.rename(row['path'],os.path.join(trainingfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
    "  print(\"Done\")\n",
    "else:\n",
    "  print(\"Training data already there... Doing nothing\")\n",
    "\n",
    "if not os.path.isdir(validationfolder):\n",
    "  print(\"Create folder structure for the validation set...\")\n",
    "  os.mkdir(validationfolder)\n",
    "  for folder in classes:\n",
    "    os.mkdir(os.path.join(validationfolder,folder))\n",
    "  print(\"Done.\\nMoving images to the respective folders...\")\n",
    "  data[data['year'].isin(yearsvalidation)].progress_apply(lambda row: os.rename(row['path'],os.path.join(validationfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
    "  print(\"Done\")  \n",
    "else:\n",
    "  print(\"Validation data already there... Doing nothing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oh9aOkEfWUEq"
   },
   "source": [
    "# Lets configure SimCLR\n",
    "Number of epocs, optimizer, resnet version to use ...\n",
    "Things that we have to configure:\n",
    "\n",
    "\n",
    "*   cuda:0 -> Change to cuda:1 to use second gpu\n",
    "*   args.batch_size -> higher value its slower but better\n",
    "*   args.resnet -> resnet18 | resnet50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dKfV68rAjVeE",
    "outputId": "0bdf18cf-9893-4d06-9b42-d60982355279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from SimCLR.utils.yaml_config_hook import yaml_config_hook\n",
    "import argparse\n",
    "\n",
    "config = yaml_config_hook(\"./SimCLR/config/config.yaml\")\n",
    "args = argparse.Namespace(**config)\n",
    "\n",
    "#Here we need to select which graphics card we want to use in case of having more than one\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using %s\" % args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "dwtMapDQjyfY",
    "outputId": "8723201a-50c0-4d2b-c7be-446827d6cff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'dataset': 'IFCB',\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epoch_num': 10,\n",
      " 'epochs': 10,\n",
      " 'fp16': False,\n",
      " 'fp16_opt_level': 'O2',\n",
      " 'image_size': 128,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'drive/My Drive/Colab Notebooks/IFCB_resnet18_b128_s128',\n",
      " 'normalize': True,\n",
      " 'optimizer': 'Adam',\n",
      " 'out_dir': 'drive/My Drive/Colab Notebooks/IFCB_resnet18_b128_s128',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'proportions': [0.01, 0.1, 1],\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 16}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "args.dataset = \"IFCB\" #This value will be used only for the output dir\n",
    "args.image_size = 128 #@param\n",
    "args.batch_size =  128 #@param\n",
    "args.resnet = \"resnet18\" #@param ['resnet18','resnet50']\n",
    "#Means that we want to start training in this epoch. We should have a file checkpoint_{}.tar in the args.model_path dir\n",
    "args.epoch_num =  10 #@param \n",
    "#How many epochs we want. If epochs = epoch num we just load the model and do nothing\n",
    "args.epochs = 10 #@param  \n",
    "#We want to save the checkpoints to google drive\n",
    "args.out_dir = \"drive/My Drive/Colab Notebooks/{}_{}_b{}_s{}\".format(args.dataset,args.resnet,args.batch_size,args.image_size)\n",
    "args.model_path = args.out_dir #This is the directory from where we want to restore checkpoints\n",
    "args.proportions = [0.01,0.1,1] #how many labeled data we are going to use for training\n",
    "\n",
    "if not os.path.isdir(args.out_dir):\n",
    "  raise SystemExit(\"The output folder {} does not exist!\".format(args.out_dir))\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPW_XQETJi6H"
   },
   "source": [
    "# Loading the training dataset\n",
    "\n",
    "Use pytorch to load the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvbF4INZJpGL"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from SimCLR.modules.transformations import TransformsSimCLR\n",
    "\n",
    "#This transform makes the magic and returns two augmented images from an original image\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=args.image_size))\n",
    "\n",
    "train_sampler = None\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=args.batch_size,\n",
    "  shuffle=(train_sampler is None),\n",
    "  drop_last=True,\n",
    "  num_workers=args.workers,\n",
    "  sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGzNgl0rvVvO"
   },
   "source": [
    "# Define the training function\n",
    "This is the function that will do all the work for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xd2u3DeVjL1p"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(args, train_loader, model, criterion, optimizer, writer):\n",
    "  loss_epoch = 0\n",
    "  start_time = time.time()\n",
    "  for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    x_i = x_i.to(args.device)\n",
    "    x_j = x_j.to(args.device)\n",
    "\n",
    "    # positive pair, with encoding\n",
    "    h_i, z_i = model(x_i)\n",
    "    h_j, z_j = model(x_j)\n",
    "\n",
    "    loss = criterion(z_i, z_j)\n",
    "\n",
    "    #if apex and args.fp16:\n",
    "    #    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    #        scaled_loss.backward()\n",
    "    #else:\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 50 == 0:\n",
    "      spent = time.time()-start_time\n",
    "      print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()} \\t Time: {spent} secs [{(args.batch_size*50)/spent} ej/sec]]\")\n",
    "      start_time = time.time()\n",
    "\n",
    "    writer.add_scalar(\"Loss/Step\", loss.item(), args.global_step)\n",
    "    loss_epoch += loss.item()\n",
    "    args.global_step += 1\n",
    "\n",
    "  return loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPt7HTMDWHGj"
   },
   "source": [
    "# Load the model\n",
    "We only reload the model if **args.epoch_num** is different from zero. This case means that we want to continue training from a checkpoint (we should have the model in the **args.model_path** dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asEk24AyUUyY"
   },
   "outputs": [],
   "source": [
    "from SimCLR.model import load_model\n",
    "model, optimizer, scheduler = load_model(args, train_loader,reload_model=(args.epoch_num!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgnQQ_UTWuNn"
   },
   "source": [
    "# Configure TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2sVEpLMWzCK"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
    "if not os.path.exists(tb_dir):\n",
    "  os.makedirs(tb_dir)\n",
    "writer = SummaryWriter(log_dir=tb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esq_Jrkh_zjB"
   },
   "source": [
    "# Load the loss function\n",
    "This function tries to minimize the difference between the two augmented variations of the image and maximize the difference between these and the rest of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XqPNffhXVCH"
   },
   "outputs": [],
   "source": [
    "from SimCLR.modules import NT_Xent\n",
    "\n",
    "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2RE3UTiAD49"
   },
   "source": [
    "# Training the CNN\n",
    "We make a checkpoint each 5 epochs just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ibd6L_Gbwnq"
   },
   "outputs": [],
   "source": [
    "from SimCLR.model import save_model\n",
    "\n",
    "args.global_step = 0\n",
    "if args.epoch_num!=0: #If we have loaded a model trained til an epoch, lets start training in the next\n",
    "  args.start_epoch=args.epoch_num+1\n",
    "args.current_epoch = args.start_epoch #Variable for controlling in which epoch we are\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "  lr = optimizer.param_groups[0]['lr']\n",
    "  loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n",
    "\n",
    "  if scheduler:\n",
    "    scheduler.step()\n",
    "\n",
    "  if epoch % 5 == 0:\n",
    "    save_model(args, model, optimizer)\n",
    "\n",
    "  writer.add_scalar(\"Loss/train epoch\", loss_epoch / len(train_loader), epoch)\n",
    "  writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "  print(f\"Epoch [{epoch+1}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\")\n",
    "  args.current_epoch += 1\n",
    "\n",
    "## end training\n",
    "if args.start_epoch!=args.epochs:\n",
    "  save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JI_kq0N1KHLa"
   },
   "outputs": [],
   "source": [
    "#!tensorboard dev upload --logdir \"$tb_dir\" --name \"IFCBv3\" --description \"Training with 2006 image size 128 batch size 256\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkJF3l3NqeFz"
   },
   "source": [
    "# **Trainining the classifier using the deep features**\n",
    "Now we will be trying to find out if the network has learnt something useful from the unlabeled data. We will train a Logistic Regression classifier with the labeled examples and testing against a validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8su48ibuaBp"
   },
   "source": [
    "# Define train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvUK4Z50t0E1"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, model, criterion, optimizer):\n",
    "  loss_epoch = 0\n",
    "  accuracy_epoch = 0\n",
    "  for step, (x, y) in enumerate(loader):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x = x.to(args.device)\n",
    "    y = y.to(args.device)\n",
    "\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "\n",
    "    predicted = output.argmax(1)\n",
    "    acc = (predicted == y).sum().item() / y.size(0)\n",
    "    accuracy_epoch += acc\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_epoch += loss.item()\n",
    "\n",
    "  return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fS3gToslt7A4"
   },
   "outputs": [],
   "source": [
    "def test(args, loader, model, criterion, optimizer):\n",
    "  loss_epoch = 0\n",
    "  accuracy_epoch = 0\n",
    "  model.eval()\n",
    "  for step, (x, y) in enumerate(loader):\n",
    "    model.zero_grad()\n",
    "\n",
    "    x = x.to(args.device)\n",
    "    y = y.to(args.device)\n",
    "\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "\n",
    "    predicted = output.argmax(1)\n",
    "    acc = (predicted == y).sum().item() / y.size(0)\n",
    "    accuracy_epoch += acc\n",
    "\n",
    "    loss_epoch += loss.item()\n",
    "\n",
    "  return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-4wy4s8uewo"
   },
   "source": [
    "# Load data\n",
    "We have to load the data again because before the data loader was doing the special agumentation for the contrastive learning. Now we only want to resize the images.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZQ03a_BuqbR"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=args.image_size).test_transform,)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=validationfolder, transform=TransformsSimCLR(size=args.image_size).test_transform,)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset,\n",
    "  batch_size=args.logistic_batch_size,\n",
    "  shuffle=False,\n",
    "  drop_last=True,\n",
    "  num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_dataset,\n",
    "  batch_size=args.logistic_batch_size,\n",
    "  shuffle=False,\n",
    "  drop_last=True,\n",
    "  num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hym2t6vSygv3"
   },
   "source": [
    "# Load de pretrained CNN and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vjDhl0Nmyk1B",
    "outputId": "7490db70-a40a-4ee3-f6c8-3434ade45132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
    "simclr_model = simclr_model.to(args.device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecG89q-C0WIi"
   },
   "source": [
    "# Compute deep features for both training and validation sets\n",
    "Here we use our CNN pretrained using contrastive learning with unlabelled data for computing the features from all the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7-kaL3kJ0nh9",
    "outputId": "88ef3ec2-afbd-42e8-fd69-c5e2488bc24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing deep features for training set...\n",
      "Step [0/511]\n",
      "Step [20/511]\n",
      "Step [40/511]\n",
      "Step [60/511]\n",
      "Step [80/511]\n",
      "Step [100/511]\n",
      "Step [120/511]\n",
      "Step [140/511]\n",
      "Step [160/511]\n",
      "Step [180/511]\n",
      "Step [200/511]\n",
      "Step [220/511]\n",
      "Step [240/511]\n",
      "Step [260/511]\n",
      "Step [280/511]\n",
      "Step [300/511]\n",
      "Step [320/511]\n",
      "Step [340/511]\n",
      "Step [360/511]\n",
      "Step [380/511]\n",
      "Step [400/511]\n",
      "Step [420/511]\n",
      "Step [440/511]\n",
      "Step [460/511]\n",
      "Step [480/511]\n",
      "Step [500/511]\n",
      "Features shape (130816, 512)\n",
      "Computing deep features for validation set...\n",
      "Step [0/1066]\n",
      "Step [20/1066]\n",
      "Step [40/1066]\n",
      "Step [60/1066]\n",
      "Step [80/1066]\n",
      "Step [100/1066]\n",
      "Step [120/1066]\n",
      "Step [140/1066]\n",
      "Step [160/1066]\n",
      "Step [180/1066]\n",
      "Step [200/1066]\n",
      "Step [220/1066]\n",
      "Step [240/1066]\n",
      "Step [260/1066]\n",
      "Step [280/1066]\n",
      "Step [300/1066]\n",
      "Step [320/1066]\n",
      "Step [340/1066]\n",
      "Step [360/1066]\n",
      "Step [380/1066]\n",
      "Step [400/1066]\n",
      "Step [420/1066]\n",
      "Step [440/1066]\n",
      "Step [460/1066]\n",
      "Step [480/1066]\n",
      "Step [500/1066]\n",
      "Step [520/1066]\n",
      "Step [540/1066]\n",
      "Step [560/1066]\n",
      "Step [580/1066]\n",
      "Step [600/1066]\n",
      "Step [620/1066]\n",
      "Step [640/1066]\n",
      "Step [660/1066]\n",
      "Step [680/1066]\n",
      "Step [700/1066]\n",
      "Step [720/1066]\n",
      "Step [740/1066]\n",
      "Step [760/1066]\n",
      "Step [780/1066]\n",
      "Step [800/1066]\n",
      "Step [820/1066]\n",
      "Step [840/1066]\n",
      "Step [860/1066]\n",
      "Step [880/1066]\n",
      "Step [900/1066]\n",
      "Step [920/1066]\n",
      "Step [940/1066]\n",
      "Step [960/1066]\n",
      "Step [980/1066]\n",
      "Step [1000/1066]\n",
      "Step [1020/1066]\n",
      "Step [1040/1066]\n",
      "Step [1060/1066]\n",
      "Features shape (272896, 512)\n",
      "Done\n",
      "Creating training dataset with 0.010000 of the original labeled data\n",
      "Creating training dataset with 0.100000 of the original labeled data\n",
      "Creating training dataset with 1.000000 of the original labeled data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_balanced_split(images, nclasses, p):\n",
    "  count = [0] * nclasses                                                      \n",
    "  for item in images:                                                         \n",
    "    count[item[1]] += 1\n",
    "  count = round(count*p)\n",
    "  indexes = []                                     \n",
    "  N = float(sum(count))\n",
    "  index = 0\n",
    "  for item in images:\n",
    "    if count[item[1]]>0:\n",
    "      count[item[1]] -= 1\n",
    "      indexes.append(index)\n",
    "    index = index + 1 \n",
    "  return indexes    \n",
    "\n",
    "#This function computes the deep features\n",
    "def inference(loader, context_model, device):\n",
    "  feature_vector = []\n",
    "  labels_vector = []\n",
    "  for step, (x, y) in enumerate(loader):\n",
    "    x = x.to(device)\n",
    "\n",
    "    # get encoding\n",
    "    with torch.no_grad():\n",
    "      h, z = context_model(x)\n",
    "\n",
    "    h = h.detach()\n",
    "\n",
    "    feature_vector.extend(h.cpu().detach().numpy())\n",
    "    labels_vector.extend(y.numpy())\n",
    "\n",
    "    if step % 20 == 0:\n",
    "      print(f\"Step [{step}/{len(loader)}]\")\n",
    "\n",
    "  feature_vector = np.array(feature_vector)\n",
    "  labels_vector = np.array(labels_vector)\n",
    "  print(\"Features shape {}\".format(feature_vector.shape))\n",
    "  return feature_vector, labels_vector\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "  print(\"Computing deep features for training set...\")\n",
    "  train_X, train_y = inference(train_loader, context_model, device)\n",
    "  print(\"Computing deep features for validation set...\")\n",
    "  test_X, test_y = inference(test_loader, context_model, device)\n",
    "  return train_X, train_y, test_X, test_y\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size, proportions):\n",
    "  #We want to create multiple train loaders with different labelled data proportions\n",
    "  train_loaders = []\n",
    "  for p in proportions:\n",
    "    print(\"Creating training dataset with %f of the original labeled data\"%p)\n",
    "    if p!=1:\n",
    "        X_train_sub,_,y_train_sub,_ = train_test_split(X_train, y_train, train_size=p, random_state=42)\n",
    "    else:\n",
    "        X_train_sub = X_train\n",
    "        y_train_sub = y_train\n",
    "    train = torch.utils.data.TensorDataset(torch.from_numpy(X_train_sub), torch.from_numpy(y_train_sub))\n",
    "    train_loaders.append(torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False))\n",
    "\n",
    "  test = torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "  test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "  return train_loaders, test_loader\n",
    "\n",
    "(train_X, train_y, test_X, test_y) = get_features(simclr_model, train_loader, test_loader, args.device)\n",
    "print(\"Done\")\n",
    "\n",
    "#We create the data loaders from the arrays with the deep features\n",
    "arr_train_loaders, arr_test_loader = create_data_loaders_from_arrays(train_X, train_y, test_X, test_y, args.logistic_batch_size,args.proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ui_xgjsjUBXj"
   },
   "source": [
    "# Lets train the classifier and see how it works!\n",
    "We are going to train the classifier using different labeled data proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHxNV321UF0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with proportion 0.010000 and 1536 labeled examples in training set\n",
      "Epoch [0/500]\t Loss: 3.6228875716527305\t Accuracy: 0.0546875\n",
      "Epoch [10/500]\t Loss: 0.7041886448860168\t Accuracy: 0.8073846726190476\n",
      "Epoch [20/500]\t Loss: 0.5533805241187414\t Accuracy: 0.8348214285714285\n",
      "Epoch [30/500]\t Loss: 0.49100516736507416\t Accuracy: 0.8512834821428572\n",
      "Epoch [40/500]\t Loss: 0.4545842558145523\t Accuracy: 0.8558407738095238\n",
      "Epoch [50/500]\t Loss: 0.42963966230551404\t Accuracy: 0.8571428571428572\n",
      "Epoch [60/500]\t Loss: 0.4108518064022064\t Accuracy: 0.8603980654761906\n",
      "Epoch [70/500]\t Loss: 0.3957797239224116\t Accuracy: 0.8702566964285715\n",
      "Epoch [80/500]\t Loss: 0.38315768788258237\t Accuracy: 0.8722098214285715\n",
      "Epoch [90/500]\t Loss: 0.3722638289133708\t Accuracy: 0.8768601190476191\n",
      "Epoch [100/500]\t Loss: 0.3626534218589465\t Accuracy: 0.8788132440476191\n",
      "Epoch [110/500]\t Loss: 0.354034885764122\t Accuracy: 0.8807663690476191\n",
      "Epoch [120/500]\t Loss: 0.34620722631613415\t Accuracy: 0.8846726190476191\n",
      "Epoch [130/500]\t Loss: 0.3390263691544533\t Accuracy: 0.8866257440476191\n",
      "Epoch [140/500]\t Loss: 0.3323853686451912\t Accuracy: 0.8892299107142857\n",
      "Epoch [150/500]\t Loss: 0.3262026806672414\t Accuracy: 0.8911830357142857\n",
      "Epoch [160/500]\t Loss: 0.32041467477877933\t Accuracy: 0.8931361607142857\n",
      "Epoch [170/500]\t Loss: 0.3149705231189728\t Accuracy: 0.8937872023809524\n",
      "Epoch [180/500]\t Loss: 0.3098290761311849\t Accuracy: 0.8950892857142857\n",
      "Epoch [190/500]\t Loss: 0.304956557850043\t Accuracy: 0.8970424107142857\n",
      "Epoch [200/500]\t Loss: 0.3003247951467832\t Accuracy: 0.8976934523809524\n",
      "Epoch [210/500]\t Loss: 0.2959100777904193\t Accuracy: 0.8983444940476191\n",
      "Epoch [220/500]\t Loss: 0.29169227679570514\t Accuracy: 0.8989955357142857\n",
      "Epoch [230/500]\t Loss: 0.287654106815656\t Accuracy: 0.8996465773809524\n",
      "Epoch [240/500]\t Loss: 0.2837806890408198\t Accuracy: 0.9022507440476191\n",
      "Epoch [250/500]\t Loss: 0.28005899613102275\t Accuracy: 0.9015997023809524\n",
      "Epoch [260/500]\t Loss: 0.2764776137967904\t Accuracy: 0.9015997023809524\n",
      "Epoch [270/500]\t Loss: 0.273026575644811\t Accuracy: 0.9035528273809524\n",
      "Epoch [280/500]\t Loss: 0.26969681431849796\t Accuracy: 0.9055059523809524\n",
      "Epoch [290/500]\t Loss: 0.2664804421365261\t Accuracy: 0.9068080357142857\n",
      "Epoch [300/500]\t Loss: 0.26337019726634026\t Accuracy: 0.9081101190476191\n",
      "Epoch [310/500]\t Loss: 0.26035962626338005\t Accuracy: 0.9107142857142857\n",
      "Epoch [320/500]\t Loss: 0.25744281460841495\t Accuracy: 0.9113653273809524\n",
      "Epoch [330/500]\t Loss: 0.25461438422401744\t Accuracy: 0.9126674107142857\n",
      "Epoch [340/500]\t Loss: 0.25186941027641296\t Accuracy: 0.9133184523809524\n",
      "Epoch [350/500]\t Loss: 0.24920339261492094\t Accuracy: 0.9133184523809524\n",
      "Epoch [360/500]\t Loss: 0.24661212290326753\t Accuracy: 0.9133184523809524\n",
      "Epoch [370/500]\t Loss: 0.2440918448070685\t Accuracy: 0.9146205357142857\n",
      "Epoch [380/500]\t Loss: 0.24163895224531493\t Accuracy: 0.9152715773809524\n",
      "Epoch [390/500]\t Loss: 0.23925014585256577\t Accuracy: 0.9152715773809524\n",
      "Epoch [400/500]\t Loss: 0.23692244167129198\t Accuracy: 0.9159226190476191\n",
      "Epoch [410/500]\t Loss: 0.23465290293097496\t Accuracy: 0.9178757440476191\n",
      "Epoch [420/500]\t Loss: 0.23243892565369606\t Accuracy: 0.9198288690476191\n",
      "Epoch [430/500]\t Loss: 0.23027805735667548\t Accuracy: 0.9211309523809524\n",
      "Epoch [440/500]\t Loss: 0.22816796352465948\t Accuracy: 0.9211309523809524\n",
      "Epoch [450/500]\t Loss: 0.22610648845632872\t Accuracy: 0.9217819940476191\n",
      "Epoch [460/500]\t Loss: 0.22409158324201903\t Accuracy: 0.9217819940476191\n",
      "Epoch [470/500]\t Loss: 0.2221213554342588\t Accuracy: 0.9224330357142857\n",
      "Epoch [480/500]\t Loss: 0.22019404793779054\t Accuracy: 0.9237351190476191\n",
      "Epoch [490/500]\t Loss: 0.21830793842673302\t Accuracy: 0.9243861607142857\n",
      "[FINAL]\t Loss: 0.8234899128187888\t Accuracy: 0.8123717460131332\n",
      "Training dataset with proportion 0.100000 and 13312 labeled examples in training set\n",
      "Epoch [0/500]\t Loss: 1.5224594313364763\t Accuracy: 0.6267908653846154\n",
      "Epoch [10/500]\t Loss: 0.47732986910985065\t Accuracy: 0.8456881009615385\n",
      "Epoch [20/500]\t Loss: 0.4428179023357538\t Accuracy: 0.8518659855769232\n",
      "Epoch [30/500]\t Loss: 0.423799016727851\t Accuracy: 0.8565414663461539\n",
      "Epoch [40/500]\t Loss: 0.41033043081943804\t Accuracy: 0.8593209134615385\n",
      "Epoch [50/500]\t Loss: 0.39966671799237913\t Accuracy: 0.8624759615384616\n",
      "Epoch [60/500]\t Loss: 0.39072055598864186\t Accuracy: 0.8652734375000001\n",
      "Epoch [70/500]\t Loss: 0.382962880226282\t Accuracy: 0.8675270432692308\n",
      "Epoch [80/500]\t Loss: 0.3760907116990823\t Accuracy: 0.8700240384615385\n",
      "Epoch [90/500]\t Loss: 0.369911108739101\t Accuracy: 0.8716015625\n",
      "Epoch [100/500]\t Loss: 0.36429306348929036\t Accuracy: 0.8734795673076923\n",
      "Epoch [110/500]\t Loss: 0.35914288776425213\t Accuracy: 0.8746814903846154\n",
      "Epoch [120/500]\t Loss: 0.3543901750101493\t Accuracy: 0.8756580528846154\n",
      "Epoch [130/500]\t Loss: 0.34997995369709456\t Accuracy: 0.8763341346153847\n",
      "Epoch [140/500]\t Loss: 0.345868356525898\t Accuracy: 0.8776111778846154\n",
      "Epoch [150/500]\t Loss: 0.34201966569973874\t Accuracy: 0.8789633413461538\n",
      "Epoch [160/500]\t Loss: 0.33840444540748227\t Accuracy: 0.8800901442307693\n",
      "Epoch [170/500]\t Loss: 0.3349979307789069\t Accuracy: 0.8812169471153847\n",
      "Epoch [180/500]\t Loss: 0.3317790561570571\t Accuracy: 0.882118389423077\n",
      "Epoch [190/500]\t Loss: 0.3287296203466562\t Accuracy: 0.8826442307692308\n",
      "Epoch [200/500]\t Loss: 0.32583386823534966\t Accuracy: 0.8839212740384615\n",
      "Epoch [210/500]\t Loss: 0.3230779394507408\t Accuracy: 0.8845222355769231\n",
      "Epoch [220/500]\t Loss: 0.3204496929851862\t Accuracy: 0.8853485576923077\n",
      "Epoch [230/500]\t Loss: 0.3179383765046413\t Accuracy: 0.8869260817307693\n",
      "Epoch [240/500]\t Loss: 0.3155344521196989\t Accuracy: 0.8874519230769231\n",
      "Epoch [250/500]\t Loss: 0.3132294427890044\t Accuracy: 0.8884284855769231\n",
      "Epoch [260/500]\t Loss: 0.3110157589499767\t Accuracy: 0.8891045673076923\n",
      "Epoch [270/500]\t Loss: 0.3088866343291906\t Accuracy: 0.8896304086538461\n",
      "Epoch [280/500]\t Loss: 0.30683599412441254\t Accuracy: 0.8898557692307693\n",
      "Epoch [290/500]\t Loss: 0.3048583547083231\t Accuracy: 0.8907572115384615\n",
      "Epoch [300/500]\t Loss: 0.3029488316522195\t Accuracy: 0.8912079326923077\n",
      "Epoch [310/500]\t Loss: 0.30110299587249756\t Accuracy: 0.891884014423077\n",
      "Epoch [320/500]\t Loss: 0.2993168252018782\t Accuracy: 0.8932361778846154\n",
      "Epoch [330/500]\t Loss: 0.2975866745870847\t Accuracy: 0.8939873798076923\n",
      "Epoch [340/500]\t Loss: 0.2959092646264113\t Accuracy: 0.8942878605769231\n",
      "Epoch [350/500]\t Loss: 0.2942815302656247\t Accuracy: 0.8953395432692308\n",
      "Epoch [360/500]\t Loss: 0.29270074545190883\t Accuracy: 0.895790264423077\n",
      "Epoch [370/500]\t Loss: 0.29116435148395026\t Accuracy: 0.896015625\n",
      "Epoch [380/500]\t Loss: 0.2896700252134066\t Accuracy: 0.8962409855769231\n",
      "Epoch [390/500]\t Loss: 0.2882155916438653\t Accuracy: 0.8965414663461538\n",
      "Epoch [400/500]\t Loss: 0.28679907895051515\t Accuracy: 0.8972175480769231\n",
      "Epoch [410/500]\t Loss: 0.2854186287866189\t Accuracy: 0.8976682692307693\n",
      "Epoch [420/500]\t Loss: 0.2840725384079493\t Accuracy: 0.89796875\n",
      "Epoch [430/500]\t Loss: 0.2827592070859212\t Accuracy: 0.898719951923077\n",
      "Epoch [440/500]\t Loss: 0.28147716791583943\t Accuracy: 0.8993960336538461\n",
      "Epoch [450/500]\t Loss: 0.28022500614707285\t Accuracy: 0.8993209134615385\n",
      "Epoch [460/500]\t Loss: 0.27900145661372405\t Accuracy: 0.8996213942307693\n",
      "Epoch [470/500]\t Loss: 0.27780529054311603\t Accuracy: 0.8998467548076923\n",
      "Epoch [480/500]\t Loss: 0.27663537888572765\t Accuracy: 0.9004477163461538\n",
      "Epoch [490/500]\t Loss: 0.27549066279943174\t Accuracy: 0.9007481971153847\n",
      "[FINAL]\t Loss: 0.6309967618190996\t Accuracy: 0.8375681578330206\n",
      "Training dataset with proportion 1.000000 and 130816 labeled examples in training set\n",
      "Epoch [0/500]\t Loss: 1.3640549953511156\t Accuracy: 0.7932286570450098\n",
      "Epoch [10/500]\t Loss: 0.5865284002033712\t Accuracy: 0.8734023361056752\n",
      "Epoch [20/500]\t Loss: 0.5738184178880416\t Accuracy: 0.874533696183953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-700b2c7873eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training dataset with proportion %f and %d labeled examples in training set\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproportions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-440dd779790a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mloss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from SimCLR.modules import LogisticRegression\n",
    "\n",
    "for i in range(len(arr_train_loaders)):\n",
    "    model = LogisticRegression(simclr_model.n_features, len(classes))\n",
    "    model = model.to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    arr_train_loader = arr_train_loaders[i]\n",
    "    print(\"Training dataset with proportion %f and %d labeled examples in training set\"%(args.proportions[i],len(arr_train_loader)*args.logistic_batch_size))\n",
    "    for epoch in range(args.logistic_epochs):\n",
    "        loss_epoch, accuracy_epoch = train(args, arr_train_loader, model, criterion, optimizer)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(arr_train_loader)}\\t Accuracy: {accuracy_epoch / len(arr_train_loader)}\")\n",
    "\n",
    "    # final testing\n",
    "    loss_epoch, accuracy_epoch = test(args, arr_test_loader, model, criterion, optimizer)\n",
    "    print(f\"[FINAL]\\t Loss: {loss_epoch / len(arr_test_loader)}\\t Accuracy: {accuracy_epoch / len(arr_test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  0.,   4.,   0.,  22.,   1.,   0.,   3.,   6.,   1.,   1.,   1.,\n",
      "         0.,   0.,   0.,   1.,   1.,   0.,   6.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,  98.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   2.,\n",
      "         0.,   2.,   8.,   0.,   5.,   8.,   4.,   7.,   4.,   1., 183.,\n",
      "        20.,   1., 884.,  18.,   8.,   3.,   0.]), array([3.000e+00, 4.200e+01, 3.000e+00, 2.190e+02, 7.000e+00, 1.000e+00,\n",
      "       3.000e+01, 6.500e+01, 1.400e+01, 1.200e+01, 9.000e+00, 2.000e+00,\n",
      "       0.000e+00, 4.000e+00, 5.000e+00, 1.000e+01, 0.000e+00, 6.300e+01,\n",
      "       0.000e+00, 4.000e+00, 3.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
      "       9.820e+02, 1.000e+00, 2.200e+01, 0.000e+00, 2.000e+00, 0.000e+00,\n",
      "       4.000e+00, 5.000e+00, 1.800e+01, 4.000e+00, 2.000e+01, 8.300e+01,\n",
      "       0.000e+00, 5.100e+01, 8.100e+01, 4.500e+01, 7.300e+01, 4.400e+01,\n",
      "       9.000e+00, 1.828e+03, 1.980e+02, 6.000e+00, 8.838e+03, 1.760e+02,\n",
      "       7.600e+01, 3.400e+01, 1.000e+00]), array([3.3000e+01, 4.1600e+02, 3.4000e+01, 2.1870e+03, 7.2000e+01,\n",
      "       9.0000e+00, 2.9700e+02, 6.4600e+02, 1.3500e+02, 1.1500e+02,\n",
      "       9.0000e+01, 2.3000e+01, 4.0000e+00, 3.9000e+01, 5.2000e+01,\n",
      "       9.8000e+01, 1.0000e+00, 6.3400e+02, 5.0000e+00, 4.3000e+01,\n",
      "       2.6000e+01, 0.0000e+00, 6.0000e+00, 1.0000e+00, 9.8180e+03,\n",
      "       6.0000e+00, 2.2200e+02, 1.0000e+00, 2.5000e+01, 1.0000e+00,\n",
      "       4.1000e+01, 5.2000e+01, 1.8000e+02, 4.4000e+01, 2.0300e+02,\n",
      "       8.3000e+02, 2.0000e+00, 5.1000e+02, 8.1300e+02, 4.4600e+02,\n",
      "       7.2600e+02, 4.4300e+02, 8.6000e+01, 1.8280e+04, 1.9850e+03,\n",
      "       6.1000e+01, 8.8382e+04, 1.7590e+03, 7.6500e+02, 3.4400e+02,\n",
      "       1.1000e+01])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7418df31ab8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_balanced_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproportions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=args.image_size).test_transform,)\n",
    "\n",
    "def create_balanced_split(images, nclasses, proportions):\n",
    "  globalcount = np.zeros(nclasses,dtype=int)                                                     \n",
    "  for item in train_dataset:\n",
    "    globalcount[item[1]] += 1\n",
    "  \n",
    "  N = float(sum(globalcount))\n",
    "  indexes = [[]]*len(p)\n",
    "  counts = []\n",
    "  for p in proportions:\n",
    "    count = globalcount*p\n",
    "    count = np.rint(count)\n",
    "    counts.append(count)\n",
    "                                    \n",
    "  for i in range(len(counts)):\n",
    "    count = counts[i]\n",
    "    j=0\n",
    "    for item in train_dataset:\n",
    "      if count[item[1]]>0:\n",
    "        count[item[1]] -= 1\n",
    "        indexes[i].append(j)\n",
    "      j = j+1\n",
    "  return indexes\n",
    "\n",
    "print(create_balanced_split(train_dataset,len(classes),args.proportions))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP5emIASnLQPb6sP3x3ZZIo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1ExTR163G6Wr9Jq8eqjQz7sAfdJJSVlqs",
   "name": "IFCB.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
