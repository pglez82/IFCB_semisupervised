{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IFCB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ExTR163G6Wr9Jq8eqjQz7sAfdJJSVlqs",
      "authorship_tag": "ABX9TyPt9O87mxNjY7X+8wgBxY+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pglez82/IFCB_semisupervised/blob/master/IFCB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aj37uariCNh",
        "colab_type": "text"
      },
      "source": [
        "# Download SimCLR code\n",
        "In this step we download the SimCLR code for **PyTorch** and install its dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU38uvtmh_HO",
        "colab_type": "code",
        "outputId": "5e51d659-16a0-4d12-c7c8-bc3d04ddf381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir(\"SimCLR\"):\n",
        "  !git clone https://github.com/spijkervet/SimCLR.git\n",
        " \n",
        "%cd SimCLR\n",
        "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
        "!pip install  pyyaml --upgrade"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SimCLR'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/74)\u001b[K\rremote: Counting objects:   2% (2/74)\u001b[K\rremote: Counting objects:   4% (3/74)\u001b[K\rremote: Counting objects:   5% (4/74)\u001b[K\rremote: Counting objects:   6% (5/74)\u001b[K\rremote: Counting objects:   8% (6/74)\u001b[K\rremote: Counting objects:   9% (7/74)\u001b[K\rremote: Counting objects:  10% (8/74)\u001b[K\rremote: Counting objects:  12% (9/74)\u001b[K\rremote: Counting objects:  13% (10/74)\u001b[K\rremote: Counting objects:  14% (11/74)\u001b[K\rremote: Counting objects:  16% (12/74)\u001b[K\rremote: Counting objects:  17% (13/74)\u001b[K\rremote: Counting objects:  18% (14/74)\u001b[K\rremote: Counting objects:  20% (15/74)\u001b[K\rremote: Counting objects:  21% (16/74)\u001b[K\rremote: Counting objects:  22% (17/74)\u001b[K\rremote: Counting objects:  24% (18/74)\u001b[K\rremote: Counting objects:  25% (19/74)\u001b[K\rremote: Counting objects:  27% (20/74)\u001b[K\rremote: Counting objects:  28% (21/74)\u001b[K\rremote: Counting objects:  29% (22/74)\u001b[K\rremote: Counting objects:  31% (23/74)\u001b[K\rremote: Counting objects:  32% (24/74)\u001b[K\rremote: Counting objects:  33% (25/74)\u001b[K\rremote: Counting objects:  35% (26/74)\u001b[K\rremote: Counting objects:  36% (27/74)\u001b[K\rremote: Counting objects:  37% (28/74)\u001b[K\rremote: Counting objects:  39% (29/74)\u001b[K\rremote: Counting objects:  40% (30/74)\u001b[K\rremote: Counting objects:  41% (31/74)\u001b[K\rremote: Counting objects:  43% (32/74)\u001b[K\rremote: Counting objects:  44% (33/74)\u001b[K\rremote: Counting objects:  45% (34/74)\u001b[K\rremote: Counting objects:  47% (35/74)\u001b[K\rremote: Counting objects:  48% (36/74)\u001b[K\rremote: Counting objects:  50% (37/74)\u001b[K\rremote: Counting objects:  51% (38/74)\u001b[K\rremote: Counting objects:  52% (39/74)\u001b[K\rremote: Counting objects:  54% (40/74)\u001b[K\rremote: Counting objects:  55% (41/74)\u001b[K\rremote: Counting objects:  56% (42/74)\u001b[K\rremote: Counting objects:  58% (43/74)\u001b[K\rremote: Counting objects:  59% (44/74)\u001b[K\rremote: Counting objects:  60% (45/74)\u001b[K\rremote: Counting objects:  62% (46/74)\u001b[K\rremote: Counting objects:  63% (47/74)\u001b[K\rremote: Counting objects:  64% (48/74)\u001b[K\rremote: Counting objects:  66% (49/74)\u001b[K\rremote: Counting objects:  67% (50/74)\u001b[K\rremote: Counting objects:  68% (51/74)\u001b[K\rremote: Counting objects:  70% (52/74)\u001b[K\rremote: Counting objects:  71% (53/74)\u001b[K\rremote: Counting objects:  72% (54/74)\u001b[K\rremote: Counting objects:  74% (55/74)\u001b[K\rremote: Counting objects:  75% (56/74)\u001b[K\rremote: Counting objects:  77% (57/74)\u001b[K\rremote: Counting objects:  78% (58/74)\u001b[K\rremote: Counting objects:  79% (59/74)\u001b[K\rremote: Counting objects:  81% (60/74)\u001b[K\rremote: Counting objects:  82% (61/74)\u001b[K\rremote: Counting objects:  83% (62/74)\u001b[K\rremote: Counting objects:  85% (63/74)\u001b[K\rremote: Counting objects:  86% (64/74)\u001b[K\rremote: Counting objects:  87% (65/74)\u001b[K\rremote: Counting objects:  89% (66/74)\u001b[K\rremote: Counting objects:  90% (67/74)\u001b[K\rremote: Counting objects:  91% (68/74)\u001b[K\rremote: Counting objects:  93% (69/74)\u001b[K\rremote: Counting objects:  94% (70/74)\u001b[K\rremote: Counting objects:  95% (71/74)\u001b[K\rremote: Counting objects:  97% (72/74)\u001b[K\rremote: Counting objects:  98% (73/74)\u001b[K\rremote: Counting objects: 100% (74/74)\u001b[K\rremote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 350 (delta 29), reused 39 (delta 13), pack-reused 276\u001b[K\n",
            "Receiving objects: 100% (350/350), 290.97 KiB | 5.94 MiB/s, done.\n",
            "Resolving deltas: 100% (178/178), done.\n",
            "/content/SimCLR/SimCLR\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.6.0a0+3c254fb)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: sacred in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.34.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (47.1.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.7.2)\n",
            "Requirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: jsonpickle<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (5.0.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (20.4)\n",
            "Requirement already satisfied: munch<3.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=18.0->sacred->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython->sacred->-r requirements.txt (line 4)) (4.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython->sacred->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.6/dist-packages (5.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6QhQvaJh75Z",
        "colab_type": "text"
      },
      "source": [
        "# Use of Google TPU [Optional]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXwwF4exiD96",
        "colab_type": "code",
        "outputId": "aa0305c8-d3d9-40b9-def2-837a15904cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "use_tpu = True #@param [\"True\",\"False\"]\n",
        "\n",
        "if use_tpu:\n",
        "  assert os.environ['COLAB_TPU_ADDR'] #make sure we are in a TPU enviroment\n",
        "  VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "  !python pytorch-xla-env-setup.py --version $VERSION\n",
        "\n",
        "  # imports the torch_xla package for TPU support\n",
        "  import torch_xla\n",
        "  import torch_xla.core.xla_model as xm\n",
        "  dev = xm.xla_device()\n",
        "  print(dev)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  53974      0 --:--:-- --:--:-- --:--:-- 53974\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200325 ...\n",
            "Uninstalling torch-1.5.0a0+d6149a7:\n",
            "  Successfully uninstalled torch-1.5.0a0+d6149a7\n",
            "Uninstalling torchvision-0.6.0a0+3c254fb:\n",
            "  Successfully uninstalled torchvision-0.6.0a0+3c254fb\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
            "Operation completed over 1 objects/83.4 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "Successfully installed torch-1.5.0a0+d6149a7\n",
            "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+e788e5b\n",
            "    Uninstalling torch-xla-1.6+e788e5b:\n",
            "      Successfully uninstalled torch-xla-1.6+e788e5b\n",
            "Successfully installed torch-xla-1.6+e788e5b\n",
            "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofyw_2IYzlMu",
        "colab_type": "text"
      },
      "source": [
        "# Download the images\n",
        "In this section, we **donwload** the data and **uncompress** it. The code has checks in order to ensure that already downloaded data is not redownloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0THo_kbFMw",
        "colab_type": "code",
        "outputId": "f3f5f4df-4ab6-494f-bbab-4aa9e0446536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if not os.path.isfile(\"IFCB_data.tar\") and not os.path.isdir(\"data\"):\n",
        "  print(\"Data do not exist in local. Downloading...\")\n",
        "  !wget -O IFCB_data.tar https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
        "else:\n",
        "  print(\"Data already exists. Skipping download.\")\n",
        "\n",
        "if not os.path.isdir(\"data\"):\n",
        "  print(\"Extracting the tar file...\")\n",
        "  !tar -xf \"IFCB_data.tar\"\n",
        "  print(\"Done. Removing the tar file.\")\n",
        "  !rm -f IFCB_data.tar #Remove the original file to save space"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data already exists. Skipping download.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUG0AmQ6z8us",
        "colab_type": "text"
      },
      "source": [
        "# Download CSV with information about the images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoVqmVot04VX",
        "colab_type": "code",
        "outputId": "eeb8a8e7-e2ef-4ae5-a98e-51aacf50f57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "if not os.path.isfile('IFCB.csv.zip'):\n",
        "  print(\"CSV data do not exist. Downloading...\")\n",
        "  !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
        "\n",
        "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        Sample  roi_number  ...       AutoClass FunctionalGroup\n",
            "0        IFCB1_2006_158_000036           1  ...             mix      Flagellate\n",
            "1        IFCB1_2006_158_000036           2  ...     ciliate_mix         Ciliate\n",
            "2        IFCB1_2006_158_000036           3  ...             mix      Flagellate\n",
            "3        IFCB1_2006_158_000036           4  ...             mix      Flagellate\n",
            "4        IFCB1_2006_158_000036           5  ...             mix      Flagellate\n",
            "...                        ...         ...  ...             ...             ...\n",
            "3457814  IFCB5_2014_353_205141        6850  ...  Leptocylindrus          Diatom\n",
            "3457815  IFCB5_2014_353_205141        6852  ...             mix      Flagellate\n",
            "3457816  IFCB5_2014_353_205141        6855  ...             mix      Flagellate\n",
            "3457817  IFCB5_2014_353_205141        6856  ...             mix      Flagellate\n",
            "3457818  IFCB5_2014_353_205141        6857  ...             mix      Flagellate\n",
            "\n",
            "[3457819 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB1gMsg5EIZV",
        "colab_type": "text"
      },
      "source": [
        "# Create training set\n",
        "\n",
        "Here we make a reestructuration of the images depending on which class we consider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX4-tijiEVcO",
        "colab_type": "code",
        "outputId": "743473c2-ef94-467c-af3e-a3e6c7c50018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import progressbar\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "classcolumn = \"AutoClass\" #Autoclass means 51 classes\n",
        "yearstraining = ['2006'] #Years to consider as training\n",
        "trainingfolder = \"training\"\n",
        "\n",
        "classes = pd.unique(data[classcolumn])\n",
        "print(\"Considering %i classes\" % len(classes))\n",
        "\n",
        "print(\"Creating training set...\")\n",
        "\n",
        "if not os.path.isdir(trainingfolder):\n",
        "  print(\"Create folder structure...\")\n",
        "  os.mkdir(trainingfolder)\n",
        "  for folder in classes:\n",
        "    os.mkdir(os.path.join(trainingfolder,folder))\n",
        "  print(\"Done.\\nMoving images to the respective folders...\")\n",
        "\n",
        "  #Compute data paths\n",
        "  data['year'] = data['Sample'].str[6:10].astype(str)\n",
        "  data['path']=\"data\"+'/'+data['year']+'/'+data['OriginalClass'].astype(str)+'/'+data['Sample'].astype(str)+'_'+data['roi_number'].apply(lambda x: str(x).zfill(5))+'.png'\n",
        "  #Move images to the training directory following the structure\n",
        "  data[data['year'].isin(yearstraining)].progress_apply(lambda row: os.rename(row['path'],os.path.join(trainingfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
        "  print(\"Done\")\n",
        "else:\n",
        "  print(\"Data structure already created.\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Considering 51 classes\n",
            "Creating training set...\n",
            "Data structure already created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPW_XQETJi6H",
        "colab_type": "text"
      },
      "source": [
        "# Loading the training dataset\n",
        "\n",
        "Use pytorch to load the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvbF4INZJpGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from modules.transformations import TransformsSimCLR\n",
        "\n",
        "#This transform makes the magic and returns two augmented images from an original image\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd2u3DeVjL1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def train(args, train_loader, model, criterion, optimizer, writer):\n",
        "  loss_epoch = 0\n",
        "  start_time = time.time()\n",
        "  for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    x_i = x_i.to(args.device)\n",
        "    x_j = x_j.to(args.device)\n",
        "\n",
        "    # positive pair, with encoding\n",
        "    h_i, z_i = model(x_i)\n",
        "    h_j, z_j = model(x_j)\n",
        "\n",
        "    loss = criterion(z_i, z_j)\n",
        "\n",
        "    #if apex and args.fp16:\n",
        "    #    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "    #        scaled_loss.backward()\n",
        "    #else:\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 50 == 0:\n",
        "      spent = time.time()-start_time\n",
        "      print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()} \\t Time: {spent} secs [{(args.batch_size*50)/spent} ej/sec]]\")\n",
        "      start_time = time.time()\n",
        "\n",
        "    writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
        "    loss_epoch += loss.item()\n",
        "    args.global_step += 1\n",
        "\n",
        "  return loss_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9aOkEfWUEq",
        "colab_type": "text"
      },
      "source": [
        "# Lets configure SimCLR\n",
        "Number of epocs, optimizer, resnet version to use ...\n",
        "Things that we have to configure:\n",
        "\n",
        "\n",
        "*   cuda:0 -> Change to cuda:1 to use second gpu\n",
        "*   args.batch_size -> higher value its slower but better\n",
        "*   args.resnet -> resnet18 | resnet50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKfV68rAjVeE",
        "colab_type": "code",
        "outputId": "99991d6f-1576-45c8-d476-62fa7490b498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "import argparse\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "#Here we need to select which graphics card we want to use in case of having more than one\n",
        "if use_tpu:\n",
        "  args.device = dev\n",
        "else:\n",
        "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using %s\" % args.device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwtMapDQjyfY",
        "colab_type": "code",
        "outputId": "187c987c-9af8-46d7-f466-1d0e4ef8d1d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "from pprint import pprint\n",
        "args.batch_size = 64 #@param\n",
        "args.resnet = \"resnet18\" #@param ['resnet18','resnet50']\n",
        "args.epoch_num =  0#@param #Means that we want to start training in this epoch. We should have a file checkpoint_{}.tar in the args.model_path dir\n",
        "#We want to save the checkpoints to google drive\n",
        "args.out_dir = \"../drive/My Drive/Colab Notebooks/IFCBv2\" #change to local directory\n",
        "args.model_path = args.out_dir #This is the directory from where we want to restore checkpoints\n",
        "if not os.path.isdir(args.out_dir):\n",
        "  raise SystemExit(\"The output folder does not exist!\")\n",
        "pprint(vars(args))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64,\n",
            " 'dataset': 'CIFAR10',\n",
            " 'device': device(type='xla', index=1),\n",
            " 'epoch_num': 0,\n",
            " 'epochs': 100,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'logistic_batch_size': 256,\n",
            " 'logistic_epochs': 500,\n",
            " 'model_path': '../drive/My Drive/Colab Notebooks/IFCBv2',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': '../drive/My Drive/Colab Notebooks/IFCBv2',\n",
            " 'pretrain': True,\n",
            " 'projection_dim': 64,\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnEU4CkTWNPi",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the model for the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3n6_SXBTkvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = None\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=(train_sampler is None),\n",
        "    drop_last=True,\n",
        "    num_workers=args.workers,\n",
        "    sampler=train_sampler,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPt7HTMDWHGj",
        "colab_type": "text"
      },
      "source": [
        "# Load the model\n",
        "We only reload the model if **args.epoch_num** is different from zero. This case means that we want to continue training from a checkpoint (we should have the model in the **args.model_path** dir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asEk24AyUUyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import load_model\n",
        "model, optimizer, scheduler = load_model(args, train_loader,reload_model=(args.epoch_num!=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgnQQ_UTWuNn",
        "colab_type": "text"
      },
      "source": [
        "# Configure TensorBoard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2sVEpLMWzCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
        "if not os.path.exists(tb_dir):\n",
        "  os.makedirs(tb_dir)\n",
        "writer = SummaryWriter(log_dir=tb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esq_Jrkh_zjB",
        "colab_type": "text"
      },
      "source": [
        "# Load the loss function\n",
        "This function tries to minimize the difference between the two augmented variations of the image and maximize the difference between these and the rest of the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XqPNffhXVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from modules import NT_Xent\n",
        "\n",
        "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2RE3UTiAD49",
        "colab_type": "text"
      },
      "source": [
        "# Training the CNN\n",
        "We make a checkpoint each 5 epochs just in case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ibd6L_Gbwnq",
        "colab_type": "code",
        "outputId": "21fb10b5-bc67-4b8f-a690-011eb6f9bad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "from model import save_model\n",
        "\n",
        "args.global_step = 0\n",
        "if args.epoch_num!=0: #If we have loaded a model trained til an epoch, lets start training in the next\n",
        "  args.start_epoch=args.epoch_num+1\n",
        "args.current_epoch = args.start_epoch #Variable for controlling in which epoch we are\n",
        "\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n",
        "\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        save_model(args, model, optimizer)\n",
        "\n",
        "    writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\n",
        "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
        "    print(\n",
        "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
        "    )\n",
        "    args.current_epoch += 1\n",
        "\n",
        "## end training\n",
        "save_model(args, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0/2046]\t Loss: 4.835808753967285 \t Time: 14.94138789176941 secs [214.1701977874992 ej/sec]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-eb0781618be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0f886f522c13>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_loader, model, criterion, optimizer, writer)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/train_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI_kq0N1KHLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard dev upload --logdir \"$tb_dir\" --name \"IFCB\" --description \"Training with 2006\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}