{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IFCB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ExTR163G6Wr9Jq8eqjQz7sAfdJJSVlqs",
      "authorship_tag": "ABX9TyP5emIASnLQPb6sP3x3ZZIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pglez82/IFCB_semisupervised/blob/master/IFCB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStEOrZz2isi",
        "colab_type": "text"
      },
      "source": [
        "# Showing system info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdydmkeg2pHa",
        "colab_type": "code",
        "outputId": "f586782b-58b6-4b4e-c49b-5060260cb783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n",
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aj37uariCNh",
        "colab_type": "text"
      },
      "source": [
        "# Download SimCLR code\n",
        "In this step we download the SimCLR code for **PyTorch** and install its dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU38uvtmh_HO",
        "colab_type": "code",
        "outputId": "816d3c4a-588d-44fa-e1a5-ec3dcfa383e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir(\"SimCLR\"):\n",
        "  !git clone https://github.com/pglez82/SimCLR.git\n",
        " \n",
        "%cd SimCLR\n",
        "!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n",
        "!pip install  pyyaml --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SimCLR\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "setup.sh: 2: setup.sh: conda: not found\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.6.0+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: sacred in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.6.0.post3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.29.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (47.1.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: munch<3.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: jsonpickle<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: docopt<1.0,>=0.3 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.6/dist-packages (from sacred->-r requirements.txt (line 4)) (20.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython->sacred->-r requirements.txt (line 4)) (4.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=18.0->sacred->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython->sacred->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.6/dist-packages (5.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofyw_2IYzlMu",
        "colab_type": "text"
      },
      "source": [
        "# Download the images\n",
        "In this section, we **donwload** the data and **uncompress** it. The code has checks in order to ensure that already downloaded data is not redownloaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0THo_kbFMw",
        "colab_type": "code",
        "outputId": "d1361d8d-fc71-456f-f7bc-f0c34bbb2088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if not os.path.isfile(\"IFCB_data.tar\") and not os.path.isdir(\"data\"):\n",
        "  print(\"Data do not exist in local. Downloading...\")\n",
        "  !wget -O IFCB_data.tar https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/Ec2z0uC4lghEg-9MjzoJ9QkBK5n74QjS-LszB9dlNrPfaw?download=1\n",
        "else:\n",
        "  print(\"Data already exists. Skipping download.\")\n",
        "\n",
        "if not os.path.isdir(\"data\"):\n",
        "  print(\"Extracting the tar file...\")\n",
        "  !tar -xf \"IFCB_data.tar\"\n",
        "  print(\"Done. Removing the tar file.\")\n",
        "  !rm -f IFCB_data.tar #Remove the original file to save space"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data already exists. Skipping download.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUG0AmQ6z8us",
        "colab_type": "text"
      },
      "source": [
        "# Download CSV with information about the images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoVqmVot04VX",
        "colab_type": "code",
        "outputId": "d7d8544a-5d77-4d64-dcf1-a368e1bbadca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "if not os.path.isfile('IFCB.csv.zip'):\n",
        "  print(\"CSV data do not exist. Downloading...\")\n",
        "  !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
        "\n",
        "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        Sample  roi_number  ...       AutoClass FunctionalGroup\n",
            "0        IFCB1_2006_158_000036           1  ...             mix      Flagellate\n",
            "1        IFCB1_2006_158_000036           2  ...     ciliate_mix         Ciliate\n",
            "2        IFCB1_2006_158_000036           3  ...             mix      Flagellate\n",
            "3        IFCB1_2006_158_000036           4  ...             mix      Flagellate\n",
            "4        IFCB1_2006_158_000036           5  ...             mix      Flagellate\n",
            "...                        ...         ...  ...             ...             ...\n",
            "3457814  IFCB5_2014_353_205141        6850  ...  Leptocylindrus          Diatom\n",
            "3457815  IFCB5_2014_353_205141        6852  ...             mix      Flagellate\n",
            "3457816  IFCB5_2014_353_205141        6855  ...             mix      Flagellate\n",
            "3457817  IFCB5_2014_353_205141        6856  ...             mix      Flagellate\n",
            "3457818  IFCB5_2014_353_205141        6857  ...             mix      Flagellate\n",
            "\n",
            "[3457819 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB1gMsg5EIZV",
        "colab_type": "text"
      },
      "source": [
        "# Create training set\n",
        "\n",
        "Here we make a reestructuration of the images depending on which class we consider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX4-tijiEVcO",
        "colab_type": "code",
        "outputId": "eebbc197-ec2d-4b57-ae36-798ed164b172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import progressbar\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "classcolumn = \"AutoClass\" #Autoclass means 51 classes\n",
        "yearstraining = ['2006'] #Years to consider as training\n",
        "yearsvalidation = ['2007']\n",
        "trainingfolder = \"training\"\n",
        "validationfolder = \"validation\"\n",
        "\n",
        "classes = pd.unique(data[classcolumn])\n",
        "print(\"Considering %i classes\" % len(classes))\n",
        "\n",
        "print(\"Computing image paths...\")\n",
        "#Compute data paths\n",
        "data['year'] = data['Sample'].str[6:10].astype(str)\n",
        "data['path']=\"data\"+'/'+data['year']+'/'+data['OriginalClass'].astype(str)+'/'+data['Sample'].astype(str)+'_'+data['roi_number'].apply(lambda x: str(x).zfill(5))+'.png'\n",
        "print('Done')\n",
        "\n",
        "if not os.path.isdir(trainingfolder):\n",
        "  print(\"Create folder structure for training set...\")\n",
        "  os.mkdir(trainingfolder)\n",
        "  for folder in classes:\n",
        "    os.mkdir(os.path.join(trainingfolder,folder))\n",
        "  print(\"Done.\\nMoving images to the respective folders...\")\n",
        "  data[data['year'].isin(yearstraining)].progress_apply(lambda row: os.rename(row['path'],os.path.join(trainingfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
        "  print(\"Done\")\n",
        "else:\n",
        "  print(\"Training data already there... Doing nothing\")\n",
        "\n",
        "if not os.path.isdir(validationfolder):\n",
        "  print(\"Create folder structure for the validation set...\")\n",
        "  os.mkdir(validationfolder)\n",
        "  for folder in classes:\n",
        "    os.mkdir(os.path.join(validationfolder,folder))\n",
        "  print(\"Done.\\nMoving images to the respective folders...\")\n",
        "  data[data['year'].isin(yearsvalidation)].progress_apply(lambda row: os.rename(row['path'],os.path.join(validationfolder,row[classcolumn],os.path.basename(row['path']))),axis=1)\n",
        "  print(\"Done\")  \n",
        "else:\n",
        "  print(\"Validation data already there... Doing nothing\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Considering 51 classes\n",
            "Computing image paths...\n",
            "Done\n",
            "Training data already there... Doing nothing\n",
            "Validation data already there... Doing nothing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh9aOkEfWUEq",
        "colab_type": "text"
      },
      "source": [
        "# Lets configure SimCLR\n",
        "Number of epocs, optimizer, resnet version to use ...\n",
        "Things that we have to configure:\n",
        "\n",
        "\n",
        "*   cuda:0 -> Change to cuda:1 to use second gpu\n",
        "*   args.batch_size -> higher value its slower but better\n",
        "*   args.resnet -> resnet18 | resnet50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKfV68rAjVeE",
        "colab_type": "code",
        "outputId": "0bdf18cf-9893-4d06-9b42-d60982355279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "from utils.yaml_config_hook import yaml_config_hook\n",
        "import argparse\n",
        "\n",
        "config = yaml_config_hook(\"./config/config.yaml\")\n",
        "args = argparse.Namespace(**config)\n",
        "\n",
        "#Here we need to select which graphics card we want to use in case of having more than one\n",
        "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using %s\" % args.device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwtMapDQjyfY",
        "colab_type": "code",
        "outputId": "8723201a-50c0-4d2b-c7be-446827d6cff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "from pprint import pprint\n",
        "args.dataset = \"IFCB\" #This value will be used only for the output dir\n",
        "args.image_size = 128 #@param\n",
        "args.batch_size =  128 #@param\n",
        "args.resnet = \"resnet18\" #@param ['resnet18','resnet50']\n",
        "#Means that we want to start training in this epoch. We should have a file checkpoint_{}.tar in the args.model_path dir\n",
        "args.epoch_num =  10 #@param \n",
        "#How many epochs we want. If epochs = epoch num we just load the model and do nothing\n",
        "args.epochs = 10 #@param  \n",
        "#We want to save the checkpoints to google drive\n",
        "args.out_dir = \"../drive/My Drive/Colab Notebooks/{}_{}_b{}_s{}\".format(args.dataset,args.resnet,args.batch_size,args.image_size)\n",
        "args.model_path = args.out_dir #This is the directory from where we want to restore checkpoints\n",
        "args.proportions = [1,10,100] #how many labeled data we are going to use for training\n",
        "\n",
        "if not os.path.isdir(args.out_dir):\n",
        "  raise SystemExit(\"The output folder {} does not exist!\".format(args.out_dir))\n",
        "pprint(vars(args))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128,\n",
            " 'dataset': 'IFCB',\n",
            " 'device': device(type='cpu'),\n",
            " 'epoch_num': 10,\n",
            " 'epochs': 10,\n",
            " 'fp16': False,\n",
            " 'fp16_opt_level': 'O2',\n",
            " 'image_size': 128,\n",
            " 'logistic_batch_size': 256,\n",
            " 'logistic_epochs': 500,\n",
            " 'model_path': '../drive/My Drive/Colab Notebooks/IFCB_resnet18_b128_s128',\n",
            " 'normalize': True,\n",
            " 'optimizer': 'Adam',\n",
            " 'out_dir': '../drive/My Drive/Colab Notebooks/IFCB_resnet18_b128_s128',\n",
            " 'pretrain': True,\n",
            " 'projection_dim': 64,\n",
            " 'proportions': [1, 10, 100],\n",
            " 'resnet': 'resnet18',\n",
            " 'seed': 42,\n",
            " 'start_epoch': 0,\n",
            " 'temperature': 0.5,\n",
            " 'weight_decay': 1e-06,\n",
            " 'workers': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPW_XQETJi6H",
        "colab_type": "text"
      },
      "source": [
        "# Loading the training dataset\n",
        "\n",
        "Use pytorch to load the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvbF4INZJpGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from modules.transformations import TransformsSimCLR\n",
        "\n",
        "#This transform makes the magic and returns two augmented images from an original image\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=args.image_size))\n",
        "\n",
        "train_sampler = None\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  train_dataset,\n",
        "  batch_size=args.batch_size,\n",
        "  shuffle=(train_sampler is None),\n",
        "  drop_last=True,\n",
        "  num_workers=args.workers,\n",
        "  sampler=train_sampler,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzNgl0rvVvO",
        "colab_type": "text"
      },
      "source": [
        "# Define the training function\n",
        "This is the function that will do all the work for one epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd2u3DeVjL1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def train(args, train_loader, model, criterion, optimizer, writer):\n",
        "  loss_epoch = 0\n",
        "  start_time = time.time()\n",
        "  for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    x_i = x_i.to(args.device)\n",
        "    x_j = x_j.to(args.device)\n",
        "\n",
        "    # positive pair, with encoding\n",
        "    h_i, z_i = model(x_i)\n",
        "    h_j, z_j = model(x_j)\n",
        "\n",
        "    loss = criterion(z_i, z_j)\n",
        "\n",
        "    #if apex and args.fp16:\n",
        "    #    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "    #        scaled_loss.backward()\n",
        "    #else:\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 50 == 0:\n",
        "      spent = time.time()-start_time\n",
        "      print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()} \\t Time: {spent} secs [{(args.batch_size*50)/spent} ej/sec]]\")\n",
        "      start_time = time.time()\n",
        "\n",
        "    writer.add_scalar(\"Loss/Step\", loss.item(), args.global_step)\n",
        "    loss_epoch += loss.item()\n",
        "    args.global_step += 1\n",
        "\n",
        "  return loss_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPt7HTMDWHGj",
        "colab_type": "text"
      },
      "source": [
        "# Load the model\n",
        "We only reload the model if **args.epoch_num** is different from zero. This case means that we want to continue training from a checkpoint (we should have the model in the **args.model_path** dir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asEk24AyUUyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import load_model\n",
        "model, optimizer, scheduler = load_model(args, train_loader,reload_model=(args.epoch_num!=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgnQQ_UTWuNn",
        "colab_type": "text"
      },
      "source": [
        "# Configure TensorBoard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2sVEpLMWzCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "tb_dir = os.path.join(args.out_dir, \"colab\")\n",
        "if not os.path.exists(tb_dir):\n",
        "  os.makedirs(tb_dir)\n",
        "writer = SummaryWriter(log_dir=tb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esq_Jrkh_zjB",
        "colab_type": "text"
      },
      "source": [
        "# Load the loss function\n",
        "This function tries to minimize the difference between the two augmented variations of the image and maximize the difference between these and the rest of the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XqPNffhXVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from modules import NT_Xent\n",
        "\n",
        "criterion = NT_Xent(args.batch_size, args.temperature, args.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2RE3UTiAD49",
        "colab_type": "text"
      },
      "source": [
        "# Training the CNN\n",
        "We make a checkpoint each 5 epochs just in case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ibd6L_Gbwnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import save_model\n",
        "\n",
        "args.global_step = 0\n",
        "if args.epoch_num!=0: #If we have loaded a model trained til an epoch, lets start training in the next\n",
        "  args.start_epoch=args.epoch_num+1\n",
        "args.current_epoch = args.start_epoch #Variable for controlling in which epoch we are\n",
        "\n",
        "for epoch in range(args.start_epoch, args.epochs):\n",
        "  lr = optimizer.param_groups[0]['lr']\n",
        "  loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n",
        "\n",
        "  if scheduler:\n",
        "    scheduler.step()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    save_model(args, model, optimizer)\n",
        "\n",
        "  writer.add_scalar(\"Loss/train epoch\", loss_epoch / len(train_loader), epoch)\n",
        "  writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
        "  print(f\"Epoch [{epoch+1}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\")\n",
        "  args.current_epoch += 1\n",
        "\n",
        "## end training\n",
        "if args.start_epoch!=args.epochs:\n",
        "  save_model(args, model, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI_kq0N1KHLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tensorboard dev upload --logdir \"$tb_dir\" --name \"IFCBv3\" --description \"Training with 2006 image size 128 batch size 256\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkJF3l3NqeFz",
        "colab_type": "text"
      },
      "source": [
        "# **Trainining the classifier using the deep features**\n",
        "Now we will be trying to find out if the network has learnt something useful from the unlabeled data. We will train a Logistic Regression classifier with the labeled examples and testing against a validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8su48ibuaBp",
        "colab_type": "text"
      },
      "source": [
        "# Define train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvUK4Z50t0E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
        "  loss_epoch = 0\n",
        "  accuracy_epoch = 0\n",
        "  for step, (x, y) in enumerate(loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x = x.to(args.device)\n",
        "    y = y.to(args.device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    predicted = output.argmax(1)\n",
        "    acc = (predicted == y).sum().item() / y.size(0)\n",
        "    accuracy_epoch += acc\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_epoch += loss.item()\n",
        "\n",
        "  return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS3gToslt7A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
        "  loss_epoch = 0\n",
        "  accuracy_epoch = 0\n",
        "  model.eval()\n",
        "  for step, (x, y) in enumerate(loader):\n",
        "    model.zero_grad()\n",
        "\n",
        "    x = x.to(args.device)\n",
        "    y = y.to(args.device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    predicted = output.argmax(1)\n",
        "    acc = (predicted == y).sum().item() / y.size(0)\n",
        "    accuracy_epoch += acc\n",
        "\n",
        "    loss_epoch += loss.item()\n",
        "\n",
        "  return loss_epoch, accuracy_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-4wy4s8uewo",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "We have to load the data again because before the data loader was doing the special agumentation for the contrastive learning. Now we only want to resize the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZQ03a_BuqbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root=trainingfolder, transform=TransformsSimCLR(size=args.image_size).test_transform,)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=validationfolder, transform=TransformsSimCLR(size=args.image_size).test_transform,)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  train_dataset,\n",
        "  batch_size=args.logistic_batch_size,\n",
        "  shuffle=False,\n",
        "  drop_last=True,\n",
        "  num_workers=args.workers,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  test_dataset,\n",
        "  batch_size=args.logistic_batch_size,\n",
        "  shuffle=False,\n",
        "  drop_last=True,\n",
        "  num_workers=args.workers,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hym2t6vSygv3",
        "colab_type": "text"
      },
      "source": [
        "# Load de pretrained CNN and its weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjDhl0Nmyk1B",
        "colab_type": "code",
        "outputId": "7490db70-a40a-4ee3-f6c8-3434ade45132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "simclr_model, _, _ = load_model(args, train_loader, reload_model=True)\n",
        "simclr_model = simclr_model.to(args.device)\n",
        "simclr_model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimCLR(\n",
              "  (encoder): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (projector): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=64, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Z4gOmYz0iC",
        "colab_type": "text"
      },
      "source": [
        "# Configure Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoltBnckzMfn",
        "colab_type": "code",
        "outputId": "695ac4c3-beb7-46d8-bb7a-98b92f514b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from modules import LogisticRegression\n",
        "\n",
        "print(\"Configuring Logistic Regression. %i features and %i classes\" % (simclr_model.n_features,len(classes)))\n",
        "model = LogisticRegression(simclr_model.n_features, len(classes))\n",
        "model = model.to(args.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Configuring Logistic Regression. 512 features and 51 classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecG89q-C0WIi",
        "colab_type": "text"
      },
      "source": [
        "# Compute deep features for both training and validation sets\n",
        "Here we use our CNN pretrained using contrastive learning with unlabelled data for computing the features from all the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kaL3kJ0nh9",
        "colab_type": "code",
        "outputId": "88ef3ec2-afbd-42e8-fd69-c5e2488bc24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#This function computes the deep features\n",
        "def inference(loader, context_model, device):\n",
        "  feature_vector = []\n",
        "  labels_vector = []\n",
        "  for step, (x, y) in enumerate(loader):\n",
        "    x = x.to(device)\n",
        "\n",
        "    # get encoding\n",
        "    with torch.no_grad():\n",
        "      h, z = context_model(x)\n",
        "\n",
        "    h = h.detach()\n",
        "\n",
        "    feature_vector.extend(h.cpu().detach().numpy())\n",
        "    labels_vector.extend(y.numpy())\n",
        "\n",
        "    if step % 20 == 0:\n",
        "      print(f\"Step [{step}/{len(loader)}]\")\n",
        "\n",
        "  feature_vector = np.array(feature_vector)\n",
        "  labels_vector = np.array(labels_vector)\n",
        "  print(\"Features shape {}\".format(feature_vector.shape))\n",
        "  return feature_vector, labels_vector\n",
        "\n",
        "def get_features(context_model, train_loader, test_loader, device):\n",
        "  print(\"Computing deep features for training set...\")\n",
        "  train_X, train_y = inference(train_loader, context_model, device)\n",
        "  print(\"Computing deep features for validation set...\")\n",
        "  test_X, test_y = inference(test_loader, context_model, device)\n",
        "  return train_X, train_y, test_X, test_y\n",
        "\n",
        "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size, proportions):\n",
        "  #We want to create multiple train loaders with different labelled data proportions\n",
        "  train_loaders = []\n",
        "  for p in proportions:\n",
        "    X_train_sub,_,y_train_sub,_ = train_test_split(X_train, y_train, train_size=p, stratify=y_train, random_state=42)\n",
        "    train = torch.utils.data.TensorDataset(torch.from_numpy(X_train_sub), torch.from_numpy(y_train_sub))\n",
        "    train_loaders.append(torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False))\n",
        "\n",
        "  test = torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "  test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "(train_X, train_y, test_X, test_y) = get_features(simclr_model, train_loader, test_loader, args.device)\n",
        "print(\"Done\")\n",
        "\n",
        "#We create the data loaders from the arrays with the deep features\n",
        "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(train_X, train_y, test_X, test_y, args.logistic_batch_size,args.proportions)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing deep features for training set...\n",
            "Step [0/511]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui_xgjsjUBXj",
        "colab_type": "text"
      },
      "source": [
        "# Lets train the classifier and see how it works!\n",
        "We are going to train the classifier using different labeled data proportions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHxNV321UF0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(args.logistic_epochs):\n",
        "  loss_epoch, accuracy_epoch = train(args, arr_train_loader, simclr_model, model, criterion, optimizer)\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
        "\n",
        "\n",
        "# final testing\n",
        "loss_epoch, accuracy_epoch = test(args, arr_test_loader, simclr_model, model, criterion, optimizer)\n",
        "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}